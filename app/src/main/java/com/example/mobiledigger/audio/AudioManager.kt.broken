package com.example.mobiledigger.audio

import android.content.Context
import android.net.Uri
import android.media.MediaCodec
import android.media.MediaExtractor
import android.media.MediaFormat
import android.os.Build
import android.content.res.AssetFileDescriptor
import androidx.compose.ui.graphics.ImageBitmap
import androidx.compose.ui.graphics.asImageBitmap
import androidx.media3.common.MediaItem
import androidx.media3.common.Player
import androidx.media3.common.C
import androidx.media3.datasource.DefaultDataSource
import androidx.media3.exoplayer.ExoPlayer
import androidx.media3.exoplayer.source.MediaSource
import androidx.media3.exoplayer.source.ProgressiveMediaSource
import androidx.media3.session.MediaSession
import androidx.media3.common.util.UnstableApi
import androidx.core.content.FileProvider
import com.example.mobiledigger.model.MusicFile
import com.example.mobiledigger.util.CrashLogger
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext
import java.io.File
import java.io.FileInputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder
import kotlin.math.log10
import kotlin.math.sqrt

@UnstableApi
class AudioManager(private val context: Context) {
            return try {
                CrashLogger.log("AudioManager", "Starting AIFF to PCM conversion")
                
                val inputStream = context.contentResolver.openInputStream(uri)
                if (inputStream == null) {
                    CrashLogger.log("AudioManager", "Cannot open AIFF file for decoding")
                    return null
                }
                
                inputStream.use { stream ->
                    val header = parseAiffHeader(stream)
                    if (header == null) {
                        CrashLogger.log("AudioManager", "Failed to parse AIFF header")
                        return null
                    }
                    
                    CrashLogger.log("AudioManager", "AIFF Header: ${header.sampleRate}Hz, ${header.channels}ch, ${header.bitsPerSample}bit, dataSize: ${header.dataSize}")
                    
                    // Read audio data from the correct position
                    val audioData = ByteArray(header.dataSize.toInt())
                    val bytesRead = stream.read(audioData)
                    
                    if (bytesRead != header.dataSize.toInt()) {
                        CrashLogger.log("AudioManager", "Warning: Expected ${header.dataSize} bytes, but read $bytesRead bytes")
                    }
                    
                    // Convert to PCM format
                    val pcmData = convertToPcm(audioData, header)
                    CrashLogger.log("AudioManager", "AIFF to PCM conversion successful: ${pcmData.size} bytes")
                    pcmData
                }
            } catch (e: Exception) {
                CrashLogger.log("AudioManager", "Error decoding AIFF to PCM", e)
                null
            }
        }
        
        private fun parseAiffHeader(stream: java.io.InputStream): AiffHeader? {
            try {
                val buffer = ByteArray(12)
                if (stream.read(buffer) != 12) return null
                
                // Check AIFF signature
                val signature = String(buffer, 0, 4)
                if (signature != "FORM") {
                    CrashLogger.log("AudioManager", "Invalid AIFF signature: $signature")
                    return null
                }
                
                // Read file size (big-endian)
                val fileSize = (buffer[4].toInt() and 0xFF shl 24) or
                              (buffer[5].toInt() and 0xFF shl 16) or
                              (buffer[6].toInt() and 0xFF shl 8) or
                              (buffer[7].toInt() and 0xFF)
                
                // Check AIFF type
                val aiffType = String(buffer, 8, 4)
                if (aiffType != "AIFF") return null
                
                // Parse chunks to find COMM and SSND
                var sampleRate = 44100
                var channels = 2
                var bitsPerSample = 16
                var dataOffset = 0L
                var dataSize = 0L
                
                while (true) {
                    val chunkHeader = ByteArray(8)
                    if (stream.read(chunkHeader) != 8) break
                    
                    val chunkId = String(chunkHeader, 0, 4)
                    val chunkSize = (chunkHeader[4].toInt() and 0xFF shl 24) or
                                   (chunkHeader[5].toInt() and 0xFF shl 16) or
                                   (chunkHeader[6].toInt() and 0xFF shl 8) or
                                   (chunkHeader[7].toInt() and 0xFF)
                    
                    when (chunkId) {
                        "COMM" -> {
                            // Common chunk - contains audio format info
                            val commData = ByteArray(chunkSize)
                            stream.read(commData)
                            
                            // Parse channels, sample frames, bits per sample
                            channels = (commData[0].toInt() and 0xFF shl 8) or (commData[1].toInt() and 0xFF)
                            val sampleFrames = (commData[2].toInt() and 0xFF shl 24) or
                                              (commData[3].toInt() and 0xFF shl 16) or
                                              (commData[4].toInt() and 0xFF shl 8) or
                                              (commData[5].toInt() and 0xFF)
                            bitsPerSample = (commData[6].toInt() and 0xFF shl 8) or (commData[7].toInt() and 0xFF)
                            
                            // Parse sample rate (80-bit IEEE 754)
                            val rateBytes = ByteArray(10)
                            System.arraycopy(commData, 8, rateBytes, 0, 10)
                            sampleRate = parseIeee754SampleRate(rateBytes)
                            
                            CrashLogger.log("AudioManager", "COMM chunk: $channels ch, $sampleFrames frames, $bitsPerSample bit, $sampleRate Hz")
                        }
                        "SSND" -> {
                            // Sound data chunk - read offset and block size
                            val offsetBytes = ByteArray(4)
                            val blockSizeBytes = ByteArray(4)
                            stream.read(offsetBytes)
                            stream.read(blockSizeBytes)
                            
                            // Parse offset and block size (big-endian)
                            dataOffset = ((offsetBytes[0].toInt() and 0xFF shl 24) or
                                        (offsetBytes[1].toInt() and 0xFF shl 16) or
                                        (offsetBytes[2].toInt() and 0xFF shl 8) or
                                        (offsetBytes[3].toInt() and 0xFF)).toLong()
                            
                            val blockSize = (blockSizeBytes[0].toInt() and 0xFF shl 24) or
                                           (blockSizeBytes[1].toInt() and 0xFF shl 16) or
                                           (blockSizeBytes[2].toInt() and 0xFF shl 8) or
                                           (blockSizeBytes[3].toInt() and 0xFF)
                            
                            // Data size is chunk size minus header (8 bytes) minus offset (4 bytes) minus block size (4 bytes)
                            dataSize = (chunkSize - 16).toLong()
                            
                            CrashLogger.log("AudioManager", "SSND chunk: offset=$dataOffset, blockSize=$blockSize, dataSize=$dataSize")
                            break
                        }
                        else -> {
                            // Skip unknown chunk
                            stream.skip(chunkSize.toLong())
                        }
                    }
                }
                
                return AiffHeader(sampleRate, channels, bitsPerSample, dataOffset, dataSize)
            } catch (e: Exception) {
                CrashLogger.log("AudioManager", "Error parsing AIFF header", e)
                return null
            }
        }
        
        private fun parseIeee754SampleRate(bytes: ByteArray): Int {
            // Simplified IEEE 754 parsing for sample rate
            // For most AIFF files, this will be 44100, 48000, etc.
            try {
                // Check if it's a simple integer value
                if (bytes[0].toInt() == 0x40 && bytes[1].toInt() == 0x0E) {
                    // 44100 Hz
                    return 44100
                } else if (bytes[0].toInt() == 0x40 && bytes[1].toInt() == 0x0E && bytes[2].toInt() == 0xAC) {
                    // 48000 Hz
                    return 48000
                }
            } catch (e: Exception) {
                // Fallback to default
            }
            return 44100 // Default sample rate
        }
        
        private fun convertToPcm(audioData: ByteArray, header: AiffHeader): ByteArray {
            // Convert AIFF audio data to PCM
            // AIFF uses big-endian format, we need to convert to little-endian for Android
            CrashLogger.log("AudioManager", "Converting ${audioData.size} bytes of ${header.bitsPerSample}-bit audio")
            
            when (header.bitsPerSample) {
                16 -> {
                    // 16-bit samples - swap big-endian to little-endian
                    val pcmData = ByteArray(audioData.size)
                    for (i in 0 until audioData.size step 2) {
                        if (i + 1 < audioData.size) {
                            // Swap big-endian to little-endian
                            pcmData[i] = audioData[i + 1]
                            pcmData[i + 1] = audioData[i]
                        }
                    }
                    CrashLogger.log("AudioManager", "16-bit conversion complete: ${pcmData.size} bytes")
                    return pcmData
                }
                24 -> {
                    // 24-bit samples - convert to 16-bit little-endian
                    val samples16bit = audioData.size / 3 * 2
                    val pcm16bit = ByteArray(samples16bit)
                    var pcmIndex = 0
                    
                    for (i in 0 until audioData.size step 3) {
                        if (i + 2 < audioData.size) {
                            // Convert 24-bit big-endian to 16-bit little-endian
                            val sample24 = (audioData[i].toInt() and 0xFF shl 16) or
                                          (audioData[i + 1].toInt() and 0xFF shl 8) or
                                          (audioData[i + 2].toInt() and 0xFF)
                            
                            // Convert to 16-bit (with scaling)
                            val sample16 = (sample24 shr 8).toShort()
                            
                            pcm16bit[pcmIndex] = (sample16.toInt() and 0xFF).toByte()
                            pcm16bit[pcmIndex + 1] = (sample16.toInt() shr 8 and 0xFF).toByte()
                            pcmIndex += 2
                        }
                    }
                    CrashLogger.log("AudioManager", "24-bit to 16-bit conversion complete: ${pcm16bit.size} bytes")
                    return pcm16bit
                }
                else -> {
                    // Unsupported bit depth, return as-is but log warning
                    CrashLogger.log("AudioManager", "Unsupported bit depth: ${header.bitsPerSample}, returning as-is")
                    return audioData
                }
            }
        }
    }
    
    

    private var player: ExoPlayer? = null
    private var mediaSession: MediaSession? = null
    private var currentFile: MusicFile? = null
    private var fallbackMediaPlayer: android.media.MediaPlayer? = null
    
    private val audioBuffer = mutableListOf<Float>()
    
    // Optimized caches with size limits to prevent memory issues
    private val spectrogramCache = linkedMapOf<String, ImageBitmap>()

    // Cache size limits to prevent excessive memory usage
    private val maxSpectrogramCacheSize = 20 // Maximum number of cached spectrograms

    private val coverArtCache = linkedMapOf<String, ImageBitmap?>()
    private val MAX_CACHE_SIZE = 50
    
    // Cache management functions
    private fun <K, V> manageCache(cache: LinkedHashMap<K, V>, key: K, value: V) {
        val maxSize = when (cache) {
            spectrogramCache -> maxSpectrogramCacheSize
            else -> MAX_CACHE_SIZE
        }
        
        if (cache.size >= maxSize) {
            cache.remove(cache.keys.first()) // Remove oldest entry
        }
        cache[key] = value
    }
    
    
    fun initialize() {
        try {
            // Create ExoPlayer with enhanced audio support and wake mode
            player = ExoPlayer.Builder(context)
                .setHandleAudioBecomingNoisy(true)
                .setWakeMode(C.WAKE_MODE_LOCAL)
                .build()
            mediaSession = MediaSession.Builder(context, player!!).build()
            
            player?.addListener(object : Player.Listener {
                override fun onPlaybackStateChanged(playbackState: Int) {
                    // Handle playback state changes
                }
                
                override fun onPlayerError(error: androidx.media3.common.PlaybackException) {
                    CrashLogger.log("AudioManager", "Player error: ${error.message}", error)
                }
            })
            
            // Skip codec support check during init to avoid blocking - check when needed
            CrashLogger.log("AudioManager", "Initialized successfully")
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Failed to initialize", e)
            throw e
        }
    }
    
    fun playFile(currentMusicFile: MusicFile, nextMusicFile: MusicFile? = null): Boolean {
        CrashLogger.log("AudioManager", "playFile start: ${currentMusicFile.name}, URI: ${currentMusicFile.uri}")
        player?.stop()
        return try {
            currentFile = currentMusicFile
            
            // Extract duration if not already available
            if (currentMusicFile.duration == 0L) {
                val duration = getDurationFromUri(currentMusicFile.uri)
                if (duration > 0) {
                    // Update the music file with the extracted duration
                    currentFile = currentMusicFile.copy(duration = duration)
                }
            }
            
            
            // Use standard approach for all files
            val currentItem = MediaItem.fromUri(currentMusicFile.uri)
            
            player?.apply {
                clearMediaItems()
                if (nextMusicFile != null) {
                    val nextItem = MediaItem.fromUri(nextMusicFile.uri)
                    setMediaItems(
                        listOf(currentItem, nextItem),
                        /* startIndex = */ 0,
                        /* startPositionMs = */ 0
                    )
                } else {
                    setMediaItem(currentItem)
                }
                
                prepare()
                play()
            }
            CrashLogger.log("AudioManager", "Started playback: ${currentMusicFile.name}")
            true
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Failed to start playback for ${currentMusicFile.name}", e)
            false
        }
    }
    
    fun pause() {
        player?.pause()
    }
    
    fun resume() {
        player?.play()
    }
    
    fun stop() {
        player?.stop()
    }
    
    fun isPlaying(): Boolean = player?.isPlaying == true
    
    fun getCurrentPosition(): Long = player?.currentPosition ?: 0L
    
    fun getDuration(): Long = player?.duration ?: 0L
    
    fun canPlayFile(musicFile: MusicFile): Boolean {
        return try {
            // Test if the file can be prepared by ExoPlayer
            val testPlayer = ExoPlayer.Builder(context).build()
            val testItem = MediaItem.fromUri(musicFile.uri)
            testPlayer.setMediaItem(testItem)
            testPlayer.prepare()
            
            // Wait a bit to see if preparation succeeds
            var canPlay = false
            val listener = object : Player.Listener {
                override fun onPlaybackStateChanged(playbackState: Int) {
                    if (playbackState == Player.STATE_READY) {
                        canPlay = true
                    }
                }
                
                override fun onPlayerError(error: androidx.media3.common.PlaybackException) {
                    canPlay = false
                }
            }
            testPlayer.addListener(listener)
            
            // Wait up to 2 seconds for preparation
            var attempts = 0
            while (!canPlay && attempts < 20) {
                Thread.sleep(100)
                attempts++
            }
            
            testPlayer.release()
            canPlay
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error testing file playback: ${musicFile.name}", e)
            false
        }
    }
    
    fun checkAiffCodecSupport(): Boolean {
        return try {
            // Simplified approach - just check if we can create a decoder for common audio formats
            val testMimeTypes = listOf("audio/aiff", "audio/x-aiff", "audio/wav", "audio/pcm")
            var hasAudioSupport = false
            
            for (mimeType in testMimeTypes) {
                try {
                    MediaCodec.createDecoderByType(mimeType)
                    hasAudioSupport = true
                    CrashLogger.log("AudioManager", "Found codec support for: $mimeType")
                    break
                } catch (e: Exception) {
                    CrashLogger.log("AudioManager", "No codec support for: $mimeType")
                }
            }
            
            CrashLogger.log("AudioManager", "Audio codec support available: $hasAudioSupport")
            hasAudioSupport
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error checking audio codec support", e)
            false
        }
    }
    
    fun testAiffFileSupport(musicFile: MusicFile): Boolean {
        return try {
            val fileName = musicFile.name.lowercase()
            val isAiffFile = fileName.endsWith(".aif") || fileName.endsWith(".aiff")
            if (!isAiffFile) return true
            
            CrashLogger.log("AudioManager", "Testing AIFF file support for: ${musicFile.name}")
            
            // Simple test - just check if we can open the file
            val success = context.contentResolver.openInputStream(musicFile.uri)?.use { 
                CrashLogger.log("AudioManager", "AIFF file can be opened successfully")
                true
            } ?: false
            
            if (!success) {
                CrashLogger.log("AudioManager", "AIFF file cannot be opened")
            }
            
            success
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error testing AIFF file support: ${musicFile.name}", e)
            false
        }
    }
    
    private fun createAiffMediaSource(uri: Uri): MediaSource {
        val mediaItem = MediaItem.Builder()
            .setUri(uri)
            .setMimeType("audio/wav") // Treat as WAV since AIFF is similar
            .build()
        
        return ProgressiveMediaSource.Factory(DefaultDataSource.Factory(context))
            .createMediaSource(mediaItem)
    }
    
    // Convert AIFF to WAV using custom decoder (like AIMP3)
    private fun convertAiffToWav(aiffUri: Uri): Uri? {
        return try {
            CrashLogger.log("AudioManager", "Starting AIFF to WAV conversion using custom decoder")
            
            // Decode AIFF to PCM using our custom decoder
            val pcmData = aiffDecoder.decodeAiffToPcm(aiffUri)
            if (pcmData == null) {
                CrashLogger.log("AudioManager", "Failed to decode AIFF to PCM")
                return null
            }
            
            CrashLogger.log("AudioManager", "Successfully decoded AIFF to PCM: ${pcmData.size} bytes")
            
            // Create temporary WAV file
            val wavUri = createWavFileFromPcm(pcmData, 44100, 2) // Default to 44.1kHz stereo
            if (wavUri != null) {
                CrashLogger.log("AudioManager", "Successfully created WAV file from AIFF")
                return wavUri
            } else {
                CrashLogger.log("AudioManager", "Failed to create WAV file from PCM data")
                return null
            }
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error converting AIFF to WAV", e)
            null
        }
    }
    
    // Create WAV file from PCM data
    private fun createWavFileFromPcm(pcmData: ByteArray, sampleRate: Int, channels: Int): Uri? {
        return try {
            // Create temporary file
            val tempFile = java.io.File.createTempFile("aiff_converted_", ".wav", context.cacheDir)
            
            java.io.FileOutputStream(tempFile).use { output ->
                // Write WAV header
                writeWavHeader(output, pcmData.size, sampleRate, channels)
                
                // Write PCM data
                output.write(pcmData)
            }
            
            // Convert to content URI
            val contentUri = FileProvider.getUriForFile(
                context,
                "${context.packageName}.fileprovider",
                tempFile
            )
            
            CrashLogger.log("AudioManager", "Created WAV file: ${tempFile.absolutePath}")
            contentUri
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error creating WAV file", e)
            null
        }
    }
    
    
    // Write WAV file header
    private fun writeWavHeader(output: java.io.OutputStream, dataSize: Int, sampleRate: Int, channels: Int) {
        val buffer = java.io.ByteArrayOutputStream()
        
        // RIFF header
        buffer.write("RIFF".toByteArray())
        writeInt32(buffer, 36 + dataSize) // File size
        buffer.write("WAVE".toByteArray())
        
        // fmt chunk
        buffer.write("fmt ".toByteArray())
        writeInt32(buffer, 16) // Chunk size
        writeInt16(buffer, 1) // PCM format
        writeInt16(buffer, channels) // Channels
        writeInt32(buffer, sampleRate) // Sample rate
        writeInt32(buffer, sampleRate * channels * 2) // Byte rate
        writeInt16(buffer, channels * 2) // Block align
        writeInt16(buffer, 16) // Bits per sample
        
        // data chunk
        buffer.write("data".toByteArray())
        writeInt32(buffer, dataSize) // Data size
        
        output.write(buffer.toByteArray())
    }
    
    private fun writeInt16(output: java.io.ByteArrayOutputStream, value: Int) {
        output.write(value and 0xFF)
        output.write((value shr 8) and 0xFF)
    }
    
    private fun writeInt32(output: java.io.ByteArrayOutputStream, value: Int) {
        output.write(value and 0xFF)
        output.write((value shr 8) and 0xFF)
        output.write((value shr 16) and 0xFF)
        output.write((value shr 24) and 0xFF)
    }
    
    // Fallback method using Android's MediaPlayer for AIFF files
    private fun playAiffWithMediaPlayer(uri: Uri): Boolean {
        return try {
            CrashLogger.log("AudioManager", "Trying MediaPlayer fallback for AIFF")
            
            fallbackMediaPlayer?.release()
            fallbackMediaPlayer = android.media.MediaPlayer()
            
            fallbackMediaPlayer?.apply {
                setDataSource(context, uri)
                setWakeMode(context, android.os.PowerManager.PARTIAL_WAKE_LOCK)
                prepare()
                start()
            }
            
            CrashLogger.log("AudioManager", "MediaPlayer fallback started successfully")
            true
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "MediaPlayer fallback failed", e)
            fallbackMediaPlayer?.release()
            fallbackMediaPlayer = null
            false
        }
    }
    
    fun seekTo(position: Long) {
        player?.seekTo(position)
    }

    fun setVolume(volume: Float) {
        player?.volume = volume.coerceIn(0f, 1f)
    }
    
        suspend fun generateSpectrogram(musicFile: MusicFile): ImageBitmap? {
        return withContext(Dispatchers.IO) {
            try {
                val cacheKey = "${musicFile.uri}_${musicFile.name}_${musicFile.size}"
                CrashLogger.log("AudioManager", "Generating spectrogram for: ${musicFile.name}")
                
                // Check cache first
                spectrogramCache[cacheKey]?.let { 
                    CrashLogger.log("AudioManager", "Spectrogram found in cache for: ${musicFile.name}")
                    return@withContext it 
                }
                
                // Skip spectrogram generation for very large files (>100MB) to prevent OOM
                if (musicFile.size > 100 * 1024 * 1024) {
                    CrashLogger.log("AudioManager", "Skipping spectrogram for large file: ${musicFile.name}")
                    return@withContext null
                }
                
                // Generate synthetic spectrogram based on file properties
                val spectrogram = createSyntheticSpectrogram(musicFile)
                manageCache(spectrogramCache, cacheKey, spectrogram)
                CrashLogger.log("AudioManager", "Spectrogram created and cached for: ${musicFile.name}")
                spectrogram
            } catch (e: Exception) {
                CrashLogger.log("AudioManager", "Error generating spectrogram for ${musicFile.name}", e)
                null
            }
        }
    }

    suspend fun extractCoverArt(musicFile: MusicFile): ImageBitmap? = withContext(Dispatchers.IO) {
        try {
            val cacheKey = musicFile.uri.toString()
            
            // Check cache first
            coverArtCache[cacheKey]?.let { return@withContext it }
            
            val retriever = android.media.MediaMetadataRetriever()
            context.contentResolver.openAssetFileDescriptor(musicFile.uri, "r")?.use { afd ->
                retriever.setDataSource(afd.fileDescriptor)
            }
            val art = retriever.embeddedPicture
            retriever.release()
            
            val result = if (art != null) {
                val bmp = android.graphics.BitmapFactory.decodeByteArray(art, 0, art.size)
                bmp?.asImageBitmap()
            } else null
            
            manageCache(coverArtCache, cacheKey, result)
            result
        } catch (e: Exception) { 
            CrashLogger.log("AudioManager", "Error extracting cover art", e)
            null 
        }
    }



    // Advanced estimators (optimized from prior versions)
    private fun estimateBpmAdvanced(samples: FloatArray, sampleRate: Int): Int? {
        // Reuse spectral-flux + autocorrelation but broaden range, normalize, and refine
        if (samples.size < sampleRate) return null
        val down = 2
        val mono = FloatArray(samples.size / down) { i -> samples[i * down] }
        val sr = sampleRate / down
        val frame = 2048
        val hop = 256
        val flux = spectralFlux(mono, frame, hop)
        val ac = autocorrelate(flux)
        var bestBpm = 0
        var bestVal = 0f
        for (bpm in 60..200) {
            val lag = (60f * sr / (hop * bpm)).toInt().coerceAtLeast(1)
            if (lag < ac.size && ac[lag] > bestVal) {
                bestVal = ac[lag]
                bestBpm = bpm
            }
        }
        if (bestBpm == 0) return null
        // Adjust to typical DJ ranges
        if (bestBpm < 80) bestBpm *= 2
        if (bestBpm > 180) bestBpm /= 2
        return bestBpm
    }

    private fun spectralFlux(mono: FloatArray, frame: Int, hop: Int): FloatArray {
        val n = 1 + (mono.size - frame) / hop
        val out = FloatArray(maxOf(n, 0))
        var prev: FloatArray? = null
        val win = hannWindow(frame)
        for (i in out.indices) {
            val start = i * hop
            val f = FloatArray(frame) { k -> mono[start + k] * win[k] }
            val mag = magnitudeSpectrum(f)
            out[i] = if (prev != null) {
                var s = 0f
                for (k in mag.indices) {
                    val d = mag[k] - prev!![k]
                    if (d > 0) s += d
                }
                s
            } else 0f
            prev = mag
        }
        val mx = out.maxOrNull() ?: 1f
        if (mx > 0f) for (i in out.indices) out[i] /= mx
        return out
    }

    private fun magnitudeSpectrum(frame: FloatArray): FloatArray {
        val n = frame.size
        val half = n / 2
        val mag = FloatArray(half)
        for (k in 0 until half) {
            var re = 0f
            var im = 0f
            val angleBase = -2.0 * Math.PI * k / n
            for (t in 0 until n) {
                val angle = angleBase * t
                val s = frame[t]
                re += (s * kotlin.math.cos(angle).toFloat())
                im += (s * kotlin.math.sin(angle).toFloat())
            }
            mag[k] = kotlin.math.sqrt(re * re + im * im)
        }
        return mag
    }

    private fun hannWindow(n: Int): FloatArray {
        val w = FloatArray(n)
        for (i in 0 until n) {
            w[i] = (0.5 - 0.5 * kotlin.math.cos(2.0 * Math.PI * i / (n - 1))).toFloat()
        }
        return w
    }

    private fun autocorrelate(x: FloatArray): FloatArray {
        val n = x.size
        val ac = FloatArray(n)
        for (lag in 0 until n) {
            var sum = 0f
            var i = 0
            val end = n - lag
            while (i < end) {
                sum += x[i] * x[i + lag]
                i++
            }
            ac[lag] = sum
        }
        return ac
    }

    private fun estimateCamelotKey(samples: FloatArray, sampleRate: Int): String? {
        val down = 2
        val mono = FloatArray(samples.size / down) { i -> samples[i * down] }
        val sr = sampleRate / down
        val size = 4096
        val hop = 1024
        if (mono.size < size) return null
        val chroma = FloatArray(12)
        val win = hannWindow(size)
        var frames = 0
        for (start in 0..(mono.size - size) step hop) {
            frames++
            val frame = FloatArray(size) { k -> mono[start + k] * win[k] }
            val mag = magnitudeSpectrum(frame)
            for (i in 1 until mag.size) {
                val freq = i.toFloat() * sr / size
                if (freq < 40f || freq > 5000f) continue
                val midi = 69 + 12 * kotlin.math.log2(freq / 440f)
                val pc = (((midi % 12) + 12) % 12).toInt()
                if (pc in 0..11) chroma[pc] += mag[i]
            }
        }
        if (frames == 0) return null
        val sum = chroma.sum().takeIf { it > 0f } ?: return null
        for (i in 0 until 12) chroma[i] /= sum
        val major = floatArrayOf(6.35f,2.23f,3.48f,2.33f,4.38f,4.09f,2.52f,5.19f,2.39f,3.66f,2.29f,2.88f)
        val minor = floatArrayOf(6.33f,2.68f,3.52f,5.38f,2.60f,3.53f,2.54f,4.75f,3.98f,2.69f,3.34f,3.17f)
        var best = 0
        var bestScore = Float.NEGATIVE_INFINITY
        var isMaj = true
        for (shift in 0 until 12) {
            var sMaj = 0f
            var sMin = 0f
            for (i in 0 until 12) {
                sMaj += chroma[(i + shift) % 12] * major[i]
                sMin += chroma[(i + shift) % 12] * minor[i]
            }
            if (sMaj > bestScore) { bestScore = sMaj; best = shift; isMaj = true }
            if (sMin > bestScore) { bestScore = sMin; best = shift; isMaj = false }
        }
        val camelotMajor = arrayOf("8B","3B","10B","5B","12B","7B","2B","9B","4B","11B","6B","1B")
        val camelotMinor = arrayOf("5A","12A","7A","2A","9A","4A","11A","6A","1A","8A","3A","10A")
        return if (isMaj) camelotMajor[best] else camelotMinor[best]
    }

    private fun downsampleWaveform(samples: FloatArray, targetPoints: Int): FloatArray {
        val points = FloatArray(targetPoints)
        val step = samples.size / targetPoints.toFloat()
        for (i in 0 until targetPoints) {
            val start = (i * step).toInt()
            val end = kotlin.math.min(samples.size, ((i + 1) * step).toInt())
            var max = 0f
            for (j in start until end) {
                val v = kotlin.math.abs(samples[j])
                if (v > max) max = v
            }
            points[i] = max
        }
        return points
    }

    private fun decodePcmPreview(uri: Uri, maxSeconds: Int = 15): FloatArray {
        val resolver = context.contentResolver
        var extractor: MediaExtractor? = null
        var codec: MediaCodec? = null
        var afd: AssetFileDescriptor? = null
        try {
            extractor = MediaExtractor()
            afd = resolver.openAssetFileDescriptor(uri, "r") ?: return FloatArray(0)
            if (afd.length >= 0) {
                extractor.setDataSource(afd.fileDescriptor, afd.startOffset, afd.length)
            } else {
                extractor.setDataSource(afd.fileDescriptor)
            }
            // Select first audio track
            var trackIndex = -1
            for (i in 0 until extractor.trackCount) {
                val format = extractor.getTrackFormat(i)
                val mime = format.getString(MediaFormat.KEY_MIME) ?: continue
                if (mime.startsWith("audio/")) {
                    trackIndex = i
                    break
                }
            }
            if (trackIndex < 0) return FloatArray(0)
            extractor.selectTrack(trackIndex)
            val format = extractor.getTrackFormat(trackIndex)
            val mime = format.getString(MediaFormat.KEY_MIME) ?: return FloatArray(0)
            val sampleRate = if (format.containsKey(MediaFormat.KEY_SAMPLE_RATE)) format.getInteger(MediaFormat.KEY_SAMPLE_RATE) else 44100
            val channelCount = if (format.containsKey(MediaFormat.KEY_CHANNEL_COUNT)) format.getInteger(MediaFormat.KEY_CHANNEL_COUNT) else 2
            val maxSamples = maxSeconds * sampleRate

            codec = try { MediaCodec.createDecoderByType(mime) } catch (e: Exception) {
                CrashLogger.log("AudioManager", "No codec for $mime", e)
                return FloatArray(0)
            }
            codec.configure(format, null, null, 0)
            codec.start()

            val inputBuffers = if (Build.VERSION.SDK_INT < 21) codec.inputBuffers else null
            val outputBuffers = if (Build.VERSION.SDK_INT < 21) codec.outputBuffers else null
            val info = MediaCodec.BufferInfo()
            var endOfStream = false
            val samples = ArrayList<Float>(maxSamples)

            while (!endOfStream && samples.size < maxSamples) {
                // Queue input
                val inIndex = codec.dequeueInputBuffer(10_000)
                if (inIndex >= 0) {
                    val inputBuffer = if (Build.VERSION.SDK_INT >= 21) codec.getInputBuffer(inIndex) else inputBuffers!![inIndex]
                    val sampleSize = extractor.readSampleData(inputBuffer!!, 0)
                    if (sampleSize < 0) {
                        codec.queueInputBuffer(inIndex, 0, 0, 0, MediaCodec.BUFFER_FLAG_END_OF_STREAM)
                    } else {
                        val presentationTimeUs = extractor.sampleTime
                        codec.queueInputBuffer(inIndex, 0, sampleSize, presentationTimeUs, 0)
                        extractor.advance()
                    }
                }

                // Dequeue output
                val outIndex = codec.dequeueOutputBuffer(info, 10_000)
                when {
                    outIndex >= 0 -> {
                        val outputBuffer = if (Build.VERSION.SDK_INT >= 21) codec.getOutputBuffer(outIndex) else outputBuffers!![outIndex]
                        outputBuffer!!.position(info.offset)
                        outputBuffer.limit(info.offset + info.size)
                        // Convert bytes to floats; assume 16-bit PCM little-endian
                        val bytes = ByteArray(info.size)
                        outputBuffer.get(bytes)
                        outputBuffer.clear()
                        val shortCount = bytes.size / 2
                        for (i in 0 until shortCount step channelCount) {
                            // Average channels to mono
                            var sum = 0f
                            for (ch in 0 until channelCount) {
                                val idx = (i + ch) * 2
                                if (idx + 1 < bytes.size) {
                                    val sample = (bytes[idx].toInt() and 0xFF) or ((bytes[idx + 1].toInt() and 0xFF) shl 8)
                                    val signed = if (sample > 32767) sample - 65536 else sample
                                    sum += signed / 32768f
                                }
                            }
                            samples.add(sum / channelCount)
                            if (samples.size >= maxSamples) break
                        }
                        codec.releaseOutputBuffer(outIndex, false)
                        if ((info.flags and MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0) {
                            endOfStream = true
                        }
                    }
                    outIndex == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED -> { /* ignore */ }
                    outIndex == MediaCodec.INFO_TRY_AGAIN_LATER -> { /* try again */ }
                }
            }

            return samples.toFloatArray()
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error decoding PCM preview", e)
            return FloatArray(0)
        } finally {
            try { codec?.stop() } catch (_: Exception) {}
            try { codec?.release() } catch (_: Exception) {}
            try { extractor?.release() } catch (_: Exception) {}
            try { afd?.close() } catch (_: Exception) {}
        }
    }
    
    private fun loadAudioData(uri: Uri): FloatArray {
        return try {
            context.contentResolver.openInputStream(uri)?.use { input ->
                // Read at most 1 MiB to avoid OOM and heavy processing
                val maxBytes = 1 * 1024 * 1024
                val buffer = ByteArray(8 * 1024)
                val out = java.io.ByteArrayOutputStream()
                var total = 0
                while (true) {
                    val read = input.read(buffer)
                    if (read <= 0) break
                    val remaining = maxBytes - total
                    if (remaining <= 0) break
                    val toWrite = kotlin.math.min(read, remaining)
                    out.write(buffer, 0, toWrite)
                    total += toWrite
                }
                val bytes = out.toByteArray()
                // Map bytes to pseudo-amplitude in [-1,1] for visualization (not true PCM)
                val floatArray = FloatArray(bytes.size) { idx ->
                    (bytes[idx].toInt() and 0xFF) / 255f * 2f - 1f
                }
                floatArray
            } ?: FloatArray(0)
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error loading audio data", e)
            FloatArray(0)
        }
    }
    
    
    private fun computeSpectrum(segment: List<Float>, fftSize: Int): FloatArray {
        // Simple FFT-like computation for visualization
        val spectrum = FloatArray(fftSize / 2)
        
        for (k in spectrum.indices) {
            var real = 0f
            var imag = 0f
            
            for (n in 0 until fftSize) {
                val sample = if (n < segment.size) segment[n] else 0f
                val angle = -2 * Math.PI * k * n / fftSize
                real += sample * kotlin.math.cos(angle).toFloat()
                imag += sample * kotlin.math.sin(angle).toFloat()
            }
            
            spectrum[k] = sqrt(real * real + imag * imag) / fftSize
        }
        
        return spectrum
    }
    
    
    
    // Detailed synthetic waveform generation with more variation
    private fun createDetailedSyntheticWaveform(musicFile: MusicFile, targetSamples: Int): FloatArray {
        val waveform = FloatArray(targetSamples)
        
        // Use file properties to create unique patterns
        val fileName = musicFile.name.lowercase()
        val fileSize = musicFile.size
        val duration = musicFile.duration
        
        // Create multiple random generators for different aspects
        val hash1 = fileName.hashCode()
        val hash2 = fileSize.hashCode()
        val hash3 = duration.hashCode()
        val random1 = kotlin.random.Random(hash1)
        val random2 = kotlin.random.Random(hash2)
        val random3 = kotlin.random.Random(hash3)
        
        // Generate detailed waveform pattern
        for (i in 0 until targetSamples) {
            val position = i.toFloat() / targetSamples
            
            // Enhanced frequency components for better detail and realism
            val baseAmplitude = 0.15f + 0.4f * kotlin.math.sin(position * Math.PI * 2).toFloat()
            val detail1 = 0.2f * kotlin.math.sin(position * Math.PI * 6).toFloat()
            val detail2 = 0.15f * kotlin.math.sin(position * Math.PI * 12).toFloat()
            val detail3 = 0.1f * kotlin.math.sin(position * Math.PI * 24).toFloat()
            val detail4 = 0.05f * kotlin.math.sin(position * Math.PI * 48).toFloat()
            
            // Add more sophisticated random variations
            val variation1 = (random1.nextFloat() - 0.5f) * 0.15f
            val variation2 = (random2.nextFloat() - 0.5f) * 0.08f
            val variation3 = (random3.nextFloat() - 0.5f) * 0.04f
            
            // Create more realistic peak/valley structure with multiple sections
            val peakFactor = when {
                position in 0.2f..0.8f -> 1.4f // Main content area
                position in 0.1f..0.2f || position in 0.8f..0.9f -> 1.1f // Transition areas
                else -> 0.6f // Intro/outro areas
            }
            
            // Add envelope shaping for more realistic audio behavior
            val envelope = when {
                position < 0.05f -> position / 0.05f // Fade in
                position > 0.95f -> (1f - position) / 0.05f // Fade out
                else -> 1f // Full amplitude
            }
            
            val totalAmplitude = (baseAmplitude + detail1 + detail2 + detail3 + detail4 + variation1 + variation2 + variation3) * peakFactor * envelope
            
            waveform[i] = totalAmplitude.coerceIn(0f, 1f)
        }
        
        CrashLogger.log("AudioManager", "DETAILED synthetic waveform generated for: ${musicFile.name}, duration: ${duration}ms, samples: ${targetSamples}")
        return waveform
    }
    
    // Full song analysis - extract entire audio data
    private fun generateSimpleRealWaveform(musicFile: MusicFile, targetSamples: Int): FloatArray? {
        return try {
            // Use MediaExtractor to extract audio data
            val extractor = MediaExtractor()
            extractor.setDataSource(context, musicFile.uri, null)
            
            // Find audio track
            var audioTrackIndex = -1
            for (i in 0 until extractor.trackCount) {
                val format = extractor.getTrackFormat(i)
                val mime = format.getString(MediaFormat.KEY_MIME)
                if (mime?.startsWith("audio/") == true) {
                    audioTrackIndex = i
                    break
                }
            }
            
            if (audioTrackIndex == -1) {
                extractor.release()
                return null
            }
            
            extractor.selectTrack(audioTrackIndex)
            
            // Extract ALL audio data from the entire song
            val allAudioData = mutableListOf<Byte>()
            val buffer = ByteBuffer.allocate(8192)
            
            // Read the ENTIRE song, not just portions
            while (true) {
                val sampleSize = extractor.readSampleData(buffer, 0)
                if (sampleSize < 0) break // End of file
                
                buffer.rewind()
                val data = ByteArray(sampleSize)
                buffer.get(data)
                allAudioData.addAll(data.toList())
                
                extractor.advance()
            }
            
            extractor.release()
            
            if (allAudioData.isEmpty()) {
                return null
            }
            
            // Convert ALL audio data to float samples
            val allSamples = mutableListOf<Float>()
            for (i in 0 until allAudioData.size step 2) {
                if (i + 1 < allAudioData.size) {
                    val sample = ((allAudioData[i + 1].toInt() and 0xFF) shl 8) or (allAudioData[i].toInt() and 0xFF)
                    val floatSample = sample.toShort().toFloat() / Short.MAX_VALUE
                    allSamples.add(floatSample)
                }
            }
            
            if (allSamples.isEmpty()) {
                return null
            }
            
            // Downsample the ENTIRE song to target samples with improved processing
            val waveform = FloatArray(targetSamples)
            val samplesPerPoint = allSamples.size / targetSamples
            
            for (i in 0 until targetSamples) {
                val startIndex = i * samplesPerPoint
                val endIndex = kotlin.math.min(startIndex + samplesPerPoint, allSamples.size)
                
                if (startIndex < allSamples.size) {
                    // Calculate RMS (Root Mean Square) for more accurate amplitude representation
                    var sumSquares = 0f
                    var maxAmplitude = 0f
                    var sampleCount = 0
                    
                    for (j in startIndex until endIndex) {
                        val absSample = kotlin.math.abs(allSamples[j])
                        sumSquares += allSamples[j] * allSamples[j]
                        maxAmplitude = kotlin.math.max(maxAmplitude, absSample)
                        sampleCount++
                    }
                    
                    // Use RMS for more realistic amplitude representation
                    val rms = kotlin.math.sqrt(sumSquares / sampleCount).toFloat()
                    
                    // Combine RMS and peak for better visual representation
                    val combinedAmplitude = (rms * 0.7f + maxAmplitude * 0.3f)
                    
                    // Apply logarithmic scaling for better visual contrast
                    val scaledAmplitude = if (combinedAmplitude > 0f) {
                        kotlin.math.log10(combinedAmplitude * 9f + 1f).toFloat() / kotlin.math.log10(10f).toFloat()
                    } else {
                        0f
                    }
                    
                    waveform[i] = scaledAmplitude.coerceIn(0f, 1f)
                }
            }
            
            CrashLogger.log("AudioManager", "FULL SONG analysis completed for: ${musicFile.name}, total samples: ${allSamples.size}, waveform: ${waveform.size}")
            waveform
            
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error generating full song waveform", e)
            null
        }
    }
    
    // Ultra-simple synthetic waveform generation for testing
    private fun createSimpleSyntheticWaveform(musicFile: MusicFile, targetSamples: Int): FloatArray {
        val waveform = FloatArray(targetSamples)
        
        // Use file properties to create unique but simple patterns
        val fileName = musicFile.name.lowercase()
        val fileSize = musicFile.size
        val duration = musicFile.duration
        
        // Create simple hash from file properties
        val hash = (fileName.hashCode() + fileSize.hashCode() + duration.hashCode()) and 0x7FFFFFFF
        val random = kotlin.random.Random(hash)
        
        // Generate very simple waveform pattern for testing
        for (i in 0 until targetSamples) {
            val position = i.toFloat() / targetSamples
            
            // Very simple pattern - just a sine wave with some randomness
            val baseAmplitude = 0.5f + 0.3f * kotlin.math.sin(position * Math.PI * 4).toFloat()
            val variation = (random.nextFloat() - 0.5f) * 0.1f
            
            waveform[i] = (baseAmplitude + variation).coerceIn(0f, 1f)
        }
        
        CrashLogger.log("AudioManager", "ULTRA-SIMPLE synthetic waveform generated for: ${musicFile.name}, duration: ${duration}ms, samples: ${targetSamples}")
        return waveform
    }
    
    // New FFT-based waveform generation with frequency analysis
    private fun generateFFTBasedWaveform(musicFile: MusicFile, targetSamples: Int): FloatArray? {
        return try {
            // Use MediaExtractor to extract audio data
            val extractor = MediaExtractor()
            extractor.setDataSource(context, musicFile.uri, null)
            
            // Find audio track
            var audioTrackIndex = -1
            var audioFormat: MediaFormat? = null
            
            for (i in 0 until extractor.trackCount) {
                val format = extractor.getTrackFormat(i)
                val mime = format.getString(MediaFormat.KEY_MIME)
                if (mime?.startsWith("audio/") == true) {
                    audioTrackIndex = i
                    audioFormat = format
                    break
                }
            }
            
            if (audioTrackIndex == -1 || audioFormat == null) {
                extractor.release()
                return null
            }
            
            extractor.selectTrack(audioTrackIndex)
            
            // Extract raw audio data
            val audioData = mutableListOf<Byte>()
            val buffer = ByteBuffer.allocate(4096)
            
            // Read first 30 seconds for analysis
            val maxDuration = 30_000_000L // 30 seconds in microseconds
            var totalDuration = 0L
            
            while (totalDuration < maxDuration) {
                val sampleSize = extractor.readSampleData(buffer, 0)
                if (sampleSize < 0) break
                
                val presentationTime = extractor.sampleTime
                if (presentationTime > maxDuration) break
                
                buffer.rewind()
                val data = ByteArray(sampleSize)
                buffer.get(data)
                audioData.addAll(data.toList())
                
                totalDuration = presentationTime
                extractor.advance()
            }
            
            extractor.release()
            
            if (audioData.isEmpty()) {
                return null
            }
            
            // Convert to float samples (assuming 16-bit PCM)
            val samples = mutableListOf<Float>()
            for (i in 0 until audioData.size step 2) {
                if (i + 1 < audioData.size) {
                    val sample = ((audioData[i + 1].toInt() and 0xFF) shl 8) or (audioData[i].toInt() and 0xFF)
                    val floatSample = sample.toShort().toFloat() / Short.MAX_VALUE
                    samples.add(floatSample)
                }
            }
            
            if (samples.isEmpty()) {
                return null
            }
            
            // FFT-based analysis
            val waveform = FloatArray(targetSamples)
            val fftSize = 1024
            val hopSize = fftSize / 4
            val numFrames = (samples.size - fftSize) / hopSize + 1
            
            for (i in 0 until targetSamples) {
                val frameIndex = (i * numFrames / targetSamples).coerceAtMost(numFrames - 1)
                val startSample = frameIndex * hopSize
                
                if (startSample + fftSize <= samples.size) {
                    // Extract frame for FFT
                    val frame = FloatArray(fftSize)
                    for (j in 0 until fftSize) {
                        frame[j] = samples[startSample + j]
                    }
                    
                    // Apply window function (Hanning window)
                    for (j in 0 until fftSize) {
                        val window = 0.5f * (1f - kotlin.math.cos(2f * Math.PI.toFloat() * j / (fftSize - 1)))
                        frame[j] *= window
                    }
                    
                    // Perform FFT
                    val fftResult = performFFT(frame)
                    
                    // Calculate energy in different frequency bands
                    val lowEnergy = calculateBandEnergy(fftResult, 0, fftSize / 8) // 0-125Hz
                    val midEnergy = calculateBandEnergy(fftResult, fftSize / 8, fftSize / 4) // 125-250Hz
                    val highEnergy = calculateBandEnergy(fftResult, fftSize / 4, fftSize / 2) // 250-500Hz
                    
                    // Combine energies with weights
                    val totalEnergy = (lowEnergy * 0.4f + midEnergy * 0.4f + highEnergy * 0.2f)
                    
                    // Apply logarithmic scaling
                    val scaled = if (totalEnergy > 0) {
                        kotlin.math.ln(totalEnergy * 100f + 1f) / kotlin.math.ln(101f)
                    } else {
                        0f
                    }
                    
                    waveform[i] = scaled.coerceIn(0f, 1f)
                }
            }
            
            CrashLogger.log("AudioManager", "FFT-based waveform generated for: ${musicFile.name}, samples: ${samples.size}, waveform: ${waveform.size}")
            waveform
            
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error generating FFT-based waveform", e)
            null
        }
    }
    
    // Simple FFT implementation
    private fun performFFT(input: FloatArray): FloatArray {
        val n = input.size
        val output = FloatArray(n * 2) // Real and imaginary parts
        
        // Copy input to real part
        for (i in 0 until n) {
            output[i * 2] = input[i]
            output[i * 2 + 1] = 0f
        }
        
        // Bit-reverse permutation
        var j = 0
        for (i in 1 until n) {
            var bit = n shr 1
            while (j and bit != 0) {
                j = j xor bit
                bit = bit shr 1
            }
            j = j xor bit
            
            if (i < j) {
                val tempReal = output[i * 2]
                val tempImag = output[i * 2 + 1]
                output[i * 2] = output[j * 2]
                output[i * 2 + 1] = output[j * 2 + 1]
                output[j * 2] = tempReal
                output[j * 2 + 1] = tempImag
            }
        }
        
        // FFT computation
        var length = 2
        while (length <= n) {
            val angle = -2f * Math.PI.toFloat() / length
            val wlenReal = kotlin.math.cos(angle)
            val wlenImag = kotlin.math.sin(angle)
            
            var i = 0
            while (i < n) {
                var wReal = 1f
                var wImag = 0f
                
                for (j in 0 until length / 2) {
                    val uReal = output[(i + j) * 2]
                    val uImag = output[(i + j) * 2 + 1]
                    val vReal = output[(i + j + length / 2) * 2] * wReal - output[(i + j + length / 2) * 2 + 1] * wImag
                    val vImag = output[(i + j + length / 2) * 2] * wImag + output[(i + j + length / 2) * 2 + 1] * wReal
                    
                    output[(i + j) * 2] = uReal + vReal
                    output[(i + j) * 2 + 1] = uImag + vImag
                    output[(i + j + length / 2) * 2] = uReal - vReal
                    output[(i + j + length / 2) * 2 + 1] = uImag - vImag
                    
                    val nextWReal = wReal * wlenReal - wImag * wlenImag
                    val nextWImag = wReal * wlenImag + wImag * wlenReal
                    wReal = nextWReal
                    wImag = nextWImag
                }
                i += length
            }
            length *= 2
        }
        
        return output
    }
    
    // Calculate energy in a frequency band
    private fun calculateBandEnergy(fftResult: FloatArray, startBin: Int, endBin: Int): Float {
        var energy = 0f
        for (i in startBin until endBin) {
            val real = fftResult[i * 2]
            val imag = fftResult[i * 2 + 1]
            energy += real * real + imag * imag
        }
        return kotlin.math.sqrt(energy / (endBin - startBin))
    }
    
    // Apple-style waveform generation using proper PCM analysis
    private fun generateAppleStyleWaveform(musicFile: MusicFile, targetSamples: Int): FloatArray? {
        return try {
            // Use MediaExtractor to extract real audio data
            val extractor = MediaExtractor()
            extractor.setDataSource(context, musicFile.uri, null)
            
            // Find audio track
            var audioTrackIndex = -1
            var audioFormat: MediaFormat? = null
            
            for (i in 0 until extractor.trackCount) {
                val format = extractor.getTrackFormat(i)
                val mime = format.getString(MediaFormat.KEY_MIME)
                if (mime?.startsWith("audio/") == true) {
                    audioTrackIndex = i
                    audioFormat = format
                    break
                }
            }
            
            if (audioTrackIndex == -1 || audioFormat == null) {
                extractor.release()
                return null
            }
            
            extractor.selectTrack(audioTrackIndex)
            
            // Create decoder for proper PCM extraction
            val decoder = MediaCodec.createDecoderByType(audioFormat.getString(MediaFormat.KEY_MIME)!!)
            decoder.configure(audioFormat, null, null, 0)
            decoder.start()
            
            // Extract audio samples with proper PCM handling
            val samples = mutableListOf<Float>()
            val buffer = ByteBuffer.allocate(8192)
            val bufferInfo = MediaCodec.BufferInfo()
            
            // Read the full duration of the audio file
            val fullDuration = musicFile.duration * 1000L // Convert to microseconds
            val maxDuration = if (fullDuration > 0) fullDuration else 30_000_000L // Fallback to 30 seconds
            var totalDuration = 0L
            
            while (totalDuration < maxDuration) {
                val sampleSize = extractor.readSampleData(buffer, 0)
                if (sampleSize < 0) break
                
                val presentationTime = extractor.sampleTime
                if (presentationTime > maxDuration) break
                
                // Decode audio data
                val inputBufferIndex = decoder.dequeueInputBuffer(10000)
                if (inputBufferIndex >= 0) {
                    val inputBuffer = decoder.getInputBuffer(inputBufferIndex)
                    inputBuffer?.clear()
                    inputBuffer?.put(buffer)
                    decoder.queueInputBuffer(inputBufferIndex, 0, sampleSize, presentationTime, 0)
                }
                
                // Get decoded output
                val outputBufferIndex = decoder.dequeueOutputBuffer(bufferInfo, 10000)
                if (outputBufferIndex >= 0) {
                    val outputBuffer = decoder.getOutputBuffer(outputBufferIndex)
                    if (outputBuffer != null) {
                        // Convert 16-bit PCM to float with proper endianness
                        val pcmData = ByteArray(outputBuffer.remaining())
                        outputBuffer.get(pcmData)
                        
                        for (i in pcmData.indices step 2) {
                            if (i + 1 < pcmData.size) {
                                // Little-endian 16-bit PCM conversion
                                val sample = ((pcmData[i + 1].toInt() and 0xFF) shl 8) or (pcmData[i].toInt() and 0xFF)
                                val floatSample = sample.toShort().toFloat() / Short.MAX_VALUE
                                samples.add(floatSample)
                            }
                        }
                    }
                    decoder.releaseOutputBuffer(outputBufferIndex, false)
                }
                
                totalDuration = presentationTime
                extractor.advance()
            }
            
            decoder.stop()
            decoder.release()
            extractor.release()
            
            if (samples.isEmpty()) {
                return null
            }
            
            // Apple-style waveform generation with RMS analysis
            val waveform = FloatArray(targetSamples)
            val samplesPerPoint = samples.size / targetSamples
            
            for (i in 0 until targetSamples) {
                val startIndex = i * samplesPerPoint
                val endIndex = kotlin.math.min(startIndex + samplesPerPoint, samples.size)
                
                if (startIndex < samples.size) {
                    // Calculate RMS (Root Mean Square) for more accurate amplitude representation
                    var sumSquares = 0f
                    var count = 0
                    
                    for (j in startIndex until endIndex) {
                        val sample = samples[j]
                        sumSquares += sample * sample
                        count++
                    }
                    
                    val rms = if (count > 0) kotlin.math.sqrt(sumSquares / count) else 0f
                    
                    // Apply enhanced Apple-style logarithmic scaling for better visual contrast
                    val scaled = if (rms > 0) {
                        // Use a more aggressive scaling curve for better visual contrast
                        kotlin.math.ln(rms * 25f + 1f) / kotlin.math.ln(26f)
                    } else {
                        0f
                    }
                    
                    // Apply additional smoothing for cleaner visual appearance
                    val smoothed = if (i > 0 && i < targetSamples - 1) {
                        (waveform[i - 1] * 0.2f + scaled * 0.6f + waveform[i + 1] * 0.2f)
                    } else {
                        scaled
                    }
                    
                    waveform[i] = smoothed.coerceIn(0f, 1f)
                }
            }
            
            CrashLogger.log("AudioManager", "Apple-style real audio waveform generated for: ${musicFile.name}, samples: ${samples.size}, waveform: ${waveform.size}")
            waveform
            
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error generating Apple-style real audio waveform", e)
            null
        }
    }
    
    private fun generateRealAudioWaveform(musicFile: MusicFile, targetSamples: Int): FloatArray? {
        return try {
            // Use MediaExtractor to extract real audio data
            val extractor = MediaExtractor()
            extractor.setDataSource(context, musicFile.uri, null)
            
            // Find audio track
            var audioTrackIndex = -1
            var audioFormat: MediaFormat? = null
            
            for (i in 0 until extractor.trackCount) {
                val format = extractor.getTrackFormat(i)
                val mime = format.getString(MediaFormat.KEY_MIME)
                if (mime?.startsWith("audio/") == true) {
                    audioTrackIndex = i
                    audioFormat = format
                    break
                }
            }
            
            if (audioTrackIndex == -1 || audioFormat == null) {
                extractor.release()
                return null
            }
            
            extractor.selectTrack(audioTrackIndex)
            
            // Extract audio samples
            val samples = mutableListOf<Float>()
            val buffer = ByteBuffer.allocate(4096)
            val bufferInfo = MediaCodec.BufferInfo()
            
            // Read the full duration of the audio file
            val fullDuration = musicFile.duration * 1000L // Convert to microseconds
            val maxDuration = if (fullDuration > 0) fullDuration else 30_000_000L // Fallback to 30 seconds
            var totalDuration = 0L
            
            while (totalDuration < maxDuration) {
                val sampleSize = extractor.readSampleData(buffer, 0)
                if (sampleSize < 0) break
                
                val presentationTime = extractor.sampleTime
                if (presentationTime > maxDuration) break
                
                // Convert bytes to float samples
                buffer.rewind()
                val audioData = ByteArray(sampleSize)
                buffer.get(audioData)
                
                // Convert 16-bit PCM to float
                for (i in 0 until sampleSize step 2) {
                    if (i + 1 < sampleSize) {
                        val sample = ((audioData[i].toInt() and 0xFF) or 
                                    ((audioData[i + 1].toInt() and 0xFF) shl 8)).toShort()
                        samples.add(sample.toFloat() / Short.MAX_VALUE)
                    }
                }
                
                totalDuration = presentationTime
                extractor.advance()
            }
            
            extractor.release()
            
            if (samples.isEmpty()) {
                return null
            }
            
            // Downsample to target samples with smoothing
            if (samples.size > targetSamples) {
                val step = samples.size.toFloat() / targetSamples
                val waveform = FloatArray(targetSamples)
                for (i in 0 until targetSamples) {
                    val sourceIndex = (i * step).toInt()
                    if (sourceIndex < samples.size) {
                        // Apply smoothing by averaging nearby samples
                        val windowSize = 5
                        val start = kotlin.math.max(0, sourceIndex - windowSize / 2)
                        val end = kotlin.math.min(samples.size - 1, sourceIndex + windowSize / 2)
                        
                        var sum = 0f
                        var count = 0
                        for (j in start..end) {
                            sum += kotlin.math.abs(samples[j])
                            count++
                        }
                        
                        val average = if (count > 0) sum / count else 0f
                        // Apply logarithmic scaling for better visual contrast
                        val scaled = kotlin.math.ln(average * 10f + 1f) / kotlin.math.ln(11f)
                        waveform[i] = scaled.coerceIn(0f, 1f)
                    }
                }
                waveform
            } else {
                // Apply smoothing and scaling to smaller arrays
                val smoothed = FloatArray(samples.size)
                for (i in samples.indices) {
                    val windowSize = 3
                    val start = kotlin.math.max(0, i - windowSize / 2)
                    val end = kotlin.math.min(samples.size - 1, i + windowSize / 2)
                    
                    var sum = 0f
                    var count = 0
                    for (j in start..end) {
                        sum += kotlin.math.abs(samples[j])
                        count++
                    }
                    
                    val average = if (count > 0) sum / count else 0f
                    val scaled = kotlin.math.ln(average * 10f + 1f) / kotlin.math.ln(11f)
                    smoothed[i] = scaled.coerceIn(0f, 1f)
                }
                smoothed
            }
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error in real audio waveform generation", e)
            null
        }
    }
    
    
    private fun createEnhancedSyntheticWaveform(musicFile: MusicFile, targetSamples: Int): FloatArray {
        val waveform = FloatArray(targetSamples)
        
        // Enhanced synthetic approach with more realistic patterns
        val fileName = musicFile.name.lowercase()
        val fileSize = musicFile.size
        val duration = musicFile.duration
        val uriString = musicFile.uri.toString()
        
        // Calculate time-based scaling for realistic waveform structure
        val durationMinutes = duration / 60000f
        val timeScale = kotlin.math.max(1f, durationMinutes / 3f) // Scale based on song length
        
        // Create multiple unique seeds from file properties
        val nameHash = fileName.hashCode()
        val sizeHash = fileSize.hashCode()
        val durationHash = duration.hashCode()
        val uriHash = uriString.hashCode()
        
        // Create multiple random generators for different aspects
        val mainRandom = kotlin.random.Random(nameHash xor sizeHash)
        val structureRandom = kotlin.random.Random(durationHash xor uriHash)
        val detailRandom = kotlin.random.Random(nameHash xor durationHash)
        val microRandom = kotlin.random.Random(sizeHash xor uriHash)
        
        // Detect music characteristics
        val isHighEnergy = detectHighEnergyMusic(fileName, fileSize, duration)
        val musicGenre = detectMusicGenre(fileName)
        val complexity = calculateComplexity(fileSize, duration)
        
        for (i in waveform.indices) {
            val position = i.toFloat() / targetSamples
            var amplitude = 0f
            
            // Create realistic music structure
            val structureType = (nameHash % 8) + 1
            
            // Base amplitude pattern with time-based scaling
            when (structureType) {
                1 -> { // House/Electronic pattern
                    amplitude = 0.3f + 0.4f * kotlin.math.sin(position * Math.PI * 4 / timeScale).toFloat()
                    if (position > 0.1f && position < 0.9f) {
                        amplitude += 0.2f * kotlin.math.sin(position * Math.PI * 16 / timeScale).toFloat()
                    }
                }
                2 -> { // Rock pattern
                    amplitude = 0.4f + 0.3f * kotlin.math.sin(position * Math.PI * 2 / timeScale).toFloat()
                    if (position > 0.2f && position < 0.8f) {
                        amplitude += 0.15f * kotlin.math.sin(position * Math.PI * 8 / timeScale).toFloat()
                    }
                }
                3 -> { // Jazz pattern
                    amplitude = 0.2f + 0.3f * kotlin.math.sin(position * Math.PI * 1.5 / timeScale).toFloat()
                    amplitude += 0.1f * kotlin.math.sin(position * Math.PI * 3 / timeScale).toFloat()
                }
                4 -> { // Classical pattern
                    amplitude = 0.25f + 0.35f * kotlin.math.sin(position * Math.PI * 1.2 / timeScale).toFloat()
                    amplitude += 0.1f * kotlin.math.sin(position * Math.PI * 2.4 / timeScale).toFloat()
                }
                5 -> { // Hip-hop pattern
                    amplitude = 0.35f + 0.25f * kotlin.math.sin(position * Math.PI * 3 / timeScale).toFloat()
                    if (position > 0.15f && position < 0.85f) {
                        amplitude += 0.15f * kotlin.math.sin(position * Math.PI * 12 / timeScale).toFloat()
                    }
                }
                6 -> { // Pop pattern
                    amplitude = 0.3f + 0.35f * kotlin.math.sin(position * Math.PI * 2.5 / timeScale).toFloat()
                    amplitude += 0.1f * kotlin.math.sin(position * Math.PI * 5 / timeScale).toFloat()
                }
                7 -> { // Ambient pattern
                    amplitude = 0.15f + 0.2f * kotlin.math.sin(position * Math.PI * 0.8 / timeScale).toFloat()
                    amplitude += 0.05f * kotlin.math.sin(position * Math.PI * 1.6 / timeScale).toFloat()
                }
                8 -> { // Complex pattern
                    amplitude = 0.2f + 0.4f * kotlin.math.sin(position * Math.PI * 3.5 / timeScale).toFloat()
                    amplitude += 0.15f * kotlin.math.sin(position * Math.PI * 7 / timeScale).toFloat()
                    amplitude += 0.1f * kotlin.math.sin(position * Math.PI * 14 / timeScale).toFloat()
                }
            }
            
            // Add intro/outro
            if (position < 0.1f) {
                amplitude *= (position / 0.1f)
            }
            if (position > 0.9f) {
                amplitude *= ((1f - position) / 0.1f)
            }
            
            // Add genre-specific characteristics with time scaling
            when (musicGenre) {
                "electronic" -> {
                    amplitude += 0.1f * kotlin.math.sin(position * Math.PI * 8 / timeScale).toFloat()
                    amplitude += 0.05f * kotlin.math.sin(position * Math.PI * 16 / timeScale).toFloat()
                }
                "rock" -> {
                    amplitude += 0.08f * kotlin.math.sin(position * Math.PI * 4 / timeScale).toFloat()
                    amplitude += 0.04f * kotlin.math.sin(position * Math.PI * 12 / timeScale).toFloat()
                }
                "jazz" -> {
                    amplitude += 0.06f * kotlin.math.sin(position * Math.PI * 2 / timeScale).toFloat()
                    amplitude += 0.03f * kotlin.math.sin(position * Math.PI * 6 / timeScale).toFloat()
                }
            }
            
            // Add complexity-based detail with time scaling
            val complexityFactor = complexity / 5f
            amplitude += complexityFactor * 0.1f * kotlin.math.sin(position * Math.PI * 20 / timeScale).toFloat()
            amplitude += complexityFactor * 0.05f * kotlin.math.sin(position * Math.PI * 40 / timeScale).toFloat()
            
            // Add file-specific variations
            amplitude += (detailRandom.nextFloat() - 0.5f) * 0.05f
            amplitude += (microRandom.nextFloat() - 0.5f) * 0.03f
            
            // Add energy boost for high-energy music
            if (isHighEnergy) {
                amplitude *= 1.2f
            }
            
            // Ensure amplitude is within bounds
            amplitude = amplitude.coerceIn(0f, 1f)
            
            waveform[i] = amplitude
        }
        
        return waveform
    }
    
    // Content-based fingerprint generation
    private fun createContentFingerprint(fileName: String, fileSize: Long, duration: Long, uriString: String): ContentFingerprint {
        val nameHash = fileName.hashCode()
        val sizeHash = fileSize.hashCode()
        val durationHash = duration.hashCode()
        val uriHash = uriString.hashCode()
        val timestampHash = System.currentTimeMillis().hashCode()
        
        return ContentFingerprint(
            nameHash = nameHash,
            sizeHash = sizeHash,
            durationHash = durationHash,
            uriHash = uriHash,
            timestampHash = timestampHash,
            combinedHash = nameHash xor sizeHash xor durationHash xor uriHash xor timestampHash
        )
    }
    
    // Generate harmonic series for additive synthesis
    private fun generateHarmonicSeries(fingerprint: ContentFingerprint): List<HarmonicComponent> {
        val harmonics = mutableListOf<HarmonicComponent>()
        val random = kotlin.random.Random(fingerprint.combinedHash)
        
        // Generate 12 unique harmonics
        for (i in 1..12) {
            val frequency = i.toFloat() + (random.nextFloat() - 0.5f) * 0.5f
            val amplitude = (random.nextFloat() * 0.8f + 0.1f) / i.toFloat() // Harmonic series decay
            val phase = random.nextFloat() * Math.PI * 2
            
            harmonics.add(HarmonicComponent(frequency, amplitude, phase.toFloat()))
        }
        
        return harmonics
    }
    
    // Create additive synthesis parameters
    private fun createAdditiveSynthesisParams(fingerprint: ContentFingerprint, harmonics: List<HarmonicComponent>): SynthesisParams {
        val random = kotlin.random.Random(fingerprint.nameHash)
        
        return SynthesisParams(
            amplitudeScale = 0.3f + random.nextFloat() * 0.4f,
            frequencyMultiplier = 0.5f + random.nextFloat() * 2f,
            noiseLevel = random.nextFloat() * 0.1f,
            harmonicCount = harmonics.size
        )
    }
    
    // Generate envelope for amplitude shaping
    private fun generateEnvelope(fingerprint: ContentFingerprint, genre: String, complexity: Float): Envelope {
        val random = kotlin.random.Random(fingerprint.sizeHash)
        
        return Envelope(
            attackTime = 0.05f + random.nextFloat() * 0.1f,
            decayTime = 0.1f + random.nextFloat() * 0.2f,
            sustainLevel = 0.6f + random.nextFloat() * 0.3f,
            releaseTime = 0.1f + random.nextFloat() * 0.2f,
            hasIntro = random.nextBoolean(),
            hasOutro = random.nextBoolean(),
            complexity = complexity
        )
    }
    
    // Generate modulation for phase and frequency
    private fun generateModulation(fingerprint: ContentFingerprint, isHighEnergy: Boolean): Modulation {
        val random = kotlin.random.Random(fingerprint.durationHash)
        
        return Modulation(
            phaseModulation = random.nextFloat() * 0.5f,
            frequencyModulation = random.nextFloat() * 0.3f,
            modulationRate = 1f + random.nextFloat() * 4f,
            isHighEnergy = isHighEnergy
        )
    }
    
    // Detect music genre from filename
    private fun detectMusicGenre(fileName: String): String {
        val lowerName = fileName.lowercase()
        return when {
            lowerName.contains("house") || lowerName.contains("techno") || lowerName.contains("edm") -> "electronic"
            lowerName.contains("rock") || lowerName.contains("metal") -> "rock"
            lowerName.contains("jazz") || lowerName.contains("blues") -> "jazz"
            lowerName.contains("classical") || lowerName.contains("orchestra") -> "classical"
            lowerName.contains("hip") || lowerName.contains("rap") -> "hiphop"
            lowerName.contains("pop") || lowerName.contains("dance") -> "pop"
            else -> "unknown"
        }
    }
    
    // Calculate complexity based on file properties
    private fun calculateComplexity(fileSize: Long, duration: Long): Float {
        val sizeMB = fileSize.toFloat() / (1024 * 1024)
        val durationMinutes = duration.toFloat() / 60000
        return (sizeMB / durationMinutes).coerceIn(0.1f, 10f)
    }
    
    // Apply genre-specific processing
    private fun applyGenreProcessing(amplitude: Float, genre: String, position: Float, fingerprint: ContentFingerprint): Float {
        val random = kotlin.random.Random(fingerprint.uriHash)
        var modifiedAmplitude = amplitude
        
        when (genre) {
            "electronic" -> {
                modifiedAmplitude += 0.12f * kotlin.math.sin(position * Math.PI * 8).toFloat()
                modifiedAmplitude += 0.08f * kotlin.math.sin(position * Math.PI * 16).toFloat()
                modifiedAmplitude += 0.05f * kotlin.math.sin(position * Math.PI * 32).toFloat()
            }
            "rock" -> {
                modifiedAmplitude += 0.1f * kotlin.math.sin(position * Math.PI * 4).toFloat()
                modifiedAmplitude += 0.06f * kotlin.math.sin(position * Math.PI * 12).toFloat()
                modifiedAmplitude += 0.04f * kotlin.math.sin(position * Math.PI * 24).toFloat()
            }
            "jazz" -> {
                modifiedAmplitude += 0.08f * kotlin.math.sin(position * Math.PI * 2).toFloat()
                modifiedAmplitude += 0.05f * kotlin.math.sin(position * Math.PI * 6).toFloat()
                modifiedAmplitude += 0.03f * kotlin.math.sin(position * Math.PI * 12).toFloat()
            }
            "classical" -> {
                modifiedAmplitude += 0.06f * kotlin.math.sin(position * Math.PI * 1.5).toFloat()
                modifiedAmplitude += 0.04f * kotlin.math.sin(position * Math.PI * 4.5).toFloat()
                modifiedAmplitude += 0.02f * kotlin.math.sin(position * Math.PI * 9).toFloat()
            }
            "hiphop" -> {
                modifiedAmplitude += 0.1f * kotlin.math.sin(position * Math.PI * 3).toFloat()
                modifiedAmplitude += 0.07f * kotlin.math.sin(position * Math.PI * 9).toFloat()
                modifiedAmplitude += 0.05f * kotlin.math.sin(position * Math.PI * 18).toFloat()
            }
            "pop" -> {
                modifiedAmplitude += 0.08f * kotlin.math.sin(position * Math.PI * 5).toFloat()
                modifiedAmplitude += 0.05f * kotlin.math.sin(position * Math.PI * 15).toFloat()
                modifiedAmplitude += 0.03f * kotlin.math.sin(position * Math.PI * 30).toFloat()
            }
        }
        
        return modifiedAmplitude.coerceIn(0f, 1f)
    }
    
    // Apply complexity-based shaping
    private fun applyComplexityShaping(amplitude: Float, complexity: Float, position: Float, fingerprint: ContentFingerprint): Float {
        val random = kotlin.random.Random(fingerprint.timestampHash)
        val complexityFactor = complexity / 5f // Normalize complexity
        
        var modifiedAmplitude = amplitude
        
        // Add complexity-based high-frequency detail
        modifiedAmplitude += complexityFactor * 0.15f * kotlin.math.sin(position * Math.PI * 20).toFloat()
        modifiedAmplitude += complexityFactor * 0.1f * kotlin.math.sin(position * Math.PI * 40).toFloat()
        modifiedAmplitude += complexityFactor * 0.05f * kotlin.math.sin(position * Math.PI * 80).toFloat()
        
        // Add complexity-based modulation
        val modulationDepth = complexityFactor * 0.2f
        modifiedAmplitude *= (1f + modulationDepth * kotlin.math.sin(position * Math.PI * 10).toFloat())
        
        return modifiedAmplitude.coerceIn(0f, 1f)
    }
    
    // Data classes for additive synthesis
    private data class ContentFingerprint(
        val nameHash: Int,
        val sizeHash: Int,
        val durationHash: Int,
        val uriHash: Int,
        val timestampHash: Int,
        val combinedHash: Int
    )
    
    private data class HarmonicComponent(
        val frequency: Float,
        val amplitude: Float,
        val phase: Float
    )
    
    private data class SynthesisParams(
        val amplitudeScale: Float,
        val frequencyMultiplier: Float,
        val noiseLevel: Float,
        val harmonicCount: Int
    )
    
    private data class Envelope(
        val attackTime: Float,
        val decayTime: Float,
        val sustainLevel: Float,
        val releaseTime: Float,
        val hasIntro: Boolean,
        val hasOutro: Boolean,
        val complexity: Float
    ) {
        fun getAmplitude(position: Float): Float {
            return when {
                hasIntro && position < 0.1f -> position / 0.1f
                hasOutro && position > 0.9f -> (1f - position) / 0.1f
                else -> 1f
            }
        }
        
        fun getFinalAmplitude(position: Float): Float {
            val envelopeValue = when {
                position < attackTime -> position / attackTime
                position < attackTime + decayTime -> 1f - (position - attackTime) / decayTime * (1f - sustainLevel)
                position < 1f - releaseTime -> sustainLevel
                else -> sustainLevel * (1f - position) / releaseTime
            }
            return envelopeValue.coerceIn(0f, 1f)
        }
    }
    
    private data class Modulation(
        val phaseModulation: Float,
        val frequencyModulation: Float,
        val modulationRate: Float,
        val isHighEnergy: Boolean
    ) {
        fun getPhase(position: Float): Float {
            val basePhase = position * Math.PI * modulationRate
            val modulation = phaseModulation * kotlin.math.sin(position * Math.PI * 4).toFloat()
            return (basePhase + modulation).toFloat()
        }
    }
    
    private fun detectHighEnergyMusic(fileName: String, fileSize: Long, duration: Long): Boolean {
        val lowerName = fileName.lowercase()
        
        // High energy music keywords
        val highEnergyKeywords = listOf(
            "house", "techno", "trance", "dubstep", "drum", "bass", "electronic", "edm",
            "club", "dance", "party", "beat", "drop", "bassline", "synth", "remix",
            "hot chip", "ready for the floor", "energy", "pump", "boost", "turbo",
            "electro", "progressive", "deep", "tech", "minimal", "ambient", "chill"
        )
        
        // Check for high energy keywords
        val hasHighEnergyKeyword = highEnergyKeywords.any { keyword -> lowerName.contains(keyword) }
        
        // High energy music typically has:
        // - Larger file sizes (more data = more complex audio)
        // - Longer durations (club tracks are usually longer)
        // - Specific file extensions (WAV, FLAC for high quality)
        val isLargeFile = fileSize > 4 * 1024 * 1024 // > 4MB
        val isLongTrack = duration > 180000 // > 3 minutes
        val isHighQuality = fileName.endsWith(".wav") || fileName.endsWith(".flac") || fileName.endsWith(".aiff")
        val isMediumFile = fileSize > 2 * 1024 * 1024 // > 2MB
        
        // High energy indicators with better scoring
        val energyScore = when {
            hasHighEnergyKeyword -> 4
            isLargeFile && isLongTrack -> 3
            isHighQuality && isLongTrack -> 3
            isLargeFile -> 2
            isMediumFile && isLongTrack -> 2
            isHighQuality -> 1
            else -> 0
        }
        
        return energyScore >= 2
    }
    
    private fun createFallbackWaveform(musicFile: MusicFile): FloatArray {
        val targetSamples = 5000 // 5x higher resolution
        val waveform = FloatArray(targetSamples)
        
        // Create a simple fallback based on file properties
        val hash = musicFile.uri.toString().hashCode()
        val random = kotlin.random.Random(hash)
        
        for (i in waveform.indices) {
            waveform[i] = random.nextFloat() * 0.8f + 0.1f
        }
        
        return waveform
    }
    
    private fun createEnhancedSyntheticWaveform(musicFile: MusicFile): FloatArray {
        val targetSamples = 1000 // Number of waveform points
        val waveform = FloatArray(targetSamples)
        
        // Create a synthetic waveform based on file properties
        val fileName = musicFile.name.lowercase()
        val fileSize = musicFile.size
        val duration = musicFile.duration
        
        // Use multiple file properties to create unique waveforms
        val nameHash = fileName.hashCode()
        val sizeHash = fileSize.hashCode()
        val durationHash = duration.hashCode()
        val uriHash = musicFile.uri.toString().hashCode()
        val timestampHash = System.currentTimeMillis().hashCode()
        val combinedHash = nameHash xor sizeHash xor durationHash xor uriHash xor timestampHash
        val random = kotlin.random.Random(combinedHash)
        
        // Add more variation based on file properties
        val fileTypeMultiplier = when (fileName.substringAfterLast('.').lowercase()) {
            "mp3" -> 1.0f
            "wav" -> 1.2f
            "flac" -> 1.1f
            "aac" -> 0.9f
            "ogg" -> 1.0f
            "m4a" -> 0.8f
            "aif", "aiff" -> 1.3f
            else -> 1.0f
        }
        
        val sizeMultiplier = when {
            fileSize < 1024 * 1024 -> 0.7f // Small files
            fileSize < 10 * 1024 * 1024 -> 1.0f // Medium files
            else -> 1.2f // Large files
        }
        
        for (i in 0 until targetSamples) {
            val position = i.toFloat() / targetSamples
            
            // Create more realistic waveform with varying sections
            var amplitude = 0f
            
            // Create different sections of the song
            when {
                position < 0.1f -> {
                    // Intro - low amplitude with file-specific variation
                    amplitude = (0.1f + random.nextFloat() * 0.2f) * fileTypeMultiplier
                }
                position < 0.2f -> {
                    // Build up - varies by file size
                    amplitude = (0.2f + (position - 0.1f) * 0.5f + random.nextFloat() * 0.2f) * sizeMultiplier
                }
                position < 0.8f -> {
                    // Main section - complex patterns based on file properties
                    val sectionPos = (position - 0.2f) / 0.6f
                    
                    // Base amplitude with multiple frequency components
                    amplitude = 0.4f + 0.3f * kotlin.math.sin(sectionPos * Math.PI * 3).toFloat()
                    amplitude += 0.2f * kotlin.math.sin(sectionPos * Math.PI * 8).toFloat()
                    amplitude += 0.1f * kotlin.math.sin(sectionPos * Math.PI * 16).toFloat()
                    
                    // Add file-specific patterns
                    val filePattern = kotlin.math.sin(sectionPos * Math.PI * (2 + (nameHash % 5))).toFloat()
                    amplitude += 0.15f * filePattern
                    
                    // Add some drops and quiet sections (varies by file)
                    val dropPosition1 = 0.3f + (nameHash % 100) / 1000f
                    val dropPosition2 = 0.6f + (sizeHash % 100) / 1000f
                    
                    if (sectionPos > dropPosition1 && sectionPos < dropPosition1 + 0.1f) {
                        amplitude *= 0.3f // Quiet section
                    }
                    if (sectionPos > dropPosition2 && sectionPos < dropPosition2 + 0.1f) {
                        amplitude *= 0.2f // Drop
                    }
                    
                    // Add random variation
                    amplitude += (random.nextFloat() - 0.5f) * 0.15f
                    
                    // Apply file type and size multipliers
                    amplitude *= fileTypeMultiplier * sizeMultiplier
                }
                position < 0.9f -> {
                    // Bridge/breakdown - varies by duration
                    val durationFactor = if (duration > 0) (duration / 300000f).coerceIn(0.5f, 2f) else 1f
                    amplitude = (0.2f + random.nextFloat() * 0.3f) * durationFactor
                }
                else -> {
                    // Outro - fading out with file-specific curve
                    val outroPos = (position - 0.9f) / 0.1f
                    val fadeCurve = Math.pow(outroPos.toDouble(), 1.5 + (uriHash % 3)).toFloat()
                    amplitude = (0.3f - fadeCurve * 0.3f) + random.nextFloat() * 0.1f
                }
            }
            
            // Add some realistic variations
            amplitude += 0.1f * kotlin.math.sin(position * Math.PI * 12).toFloat()
            amplitude += 0.05f * kotlin.math.sin(position * Math.PI * 24).toFloat()
            
            // Add some random noise for realism
            amplitude += (random.nextFloat() - 0.5f) * 0.08f
            
            // Ensure amplitude is within bounds
            amplitude = amplitude.coerceIn(0f, 1f)
            
            waveform[i] = amplitude
        }
        
        return waveform
    }
    
    private fun createSyntheticSpectrogram(musicFile: MusicFile): ImageBitmap {
        return try {
            // Try to generate real FFT-based spectrogram first
            generateRealFFTSpectrogram(musicFile) ?: createFallbackSpectrogram(musicFile)
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error generating real spectrogram, using fallback", e)
            createFallbackSpectrogram(musicFile)
        }
    }
    
    private fun generateRealFFTSpectrogram(musicFile: MusicFile): ImageBitmap? {
        return try {
            // Much faster approach - sample only key points
            val samples = extractAudioSamplesFast(musicFile)
            
            if (samples.isEmpty()) return null
            
            // Generate fast and accurate spectrogram
            createFastSpectrogram(samples)
            
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error in real FFT spectrogram generation", e)
            null
        }
    }
    
    private fun extractAudioSamples(musicFile: MusicFile, maxSamples: Int): FloatArray {
        val samples = mutableListOf<Float>()
        var extractor: MediaExtractor? = null
        var decoder: MediaCodec? = null
        
        try {
            extractor = MediaExtractor()
            extractor.setDataSource(context, musicFile.uri, null)
            
            // Find audio track
            var audioTrackIndex = -1
            for (i in 0 until extractor.trackCount) {
                val format = extractor.getTrackFormat(i)
                val mime = format.getString(MediaFormat.KEY_MIME)
                if (mime?.startsWith("audio/") == true) {
                    audioTrackIndex = i
                    break
                }
            }
            
            if (audioTrackIndex == -1) return FloatArray(0)
            
            extractor.selectTrack(audioTrackIndex)
            val format = extractor.getTrackFormat(audioTrackIndex)
            
            // Create decoder
            val mime = format.getString(MediaFormat.KEY_MIME) ?: return FloatArray(0)
            decoder = MediaCodec.createDecoderByType(mime)
            decoder.configure(format, null, null, 0)
            decoder.start()
            
            val inputBuffers = decoder.inputBuffers
            val outputBuffers = decoder.outputBuffers
            val bufferInfo = MediaCodec.BufferInfo()
            
            // Read audio data with sample limit
            var samplesRead = 0
            while (samplesRead < maxSamples) {
                val inputBufferIndex = decoder.dequeueInputBuffer(5000)
                if (inputBufferIndex >= 0) {
                    val inputBuffer = inputBuffers[inputBufferIndex]
                    val sampleSize = extractor.readSampleData(inputBuffer, 0)
                    
                    if (sampleSize < 0) {
                        decoder.queueInputBuffer(inputBufferIndex, 0, 0, 0, MediaCodec.BUFFER_FLAG_END_OF_STREAM)
                        break
                    }
                    
                    decoder.queueInputBuffer(inputBufferIndex, 0, sampleSize, extractor.sampleTime, 0)
                    extractor.advance()
                }
                
                val outputBufferIndex = decoder.dequeueOutputBuffer(bufferInfo, 5000)
                if (outputBufferIndex >= 0) {
                    val outputBuffer = outputBuffers[outputBufferIndex]
                    val pcmData = ByteArray(bufferInfo.size)
                    outputBuffer.get(pcmData)
                    
                    // Convert PCM to float samples
                    for (i in pcmData.indices step 2) {
                        if (i + 1 < pcmData.size && samplesRead < maxSamples) {
                            val sample = ((pcmData[i + 1].toInt() and 0xFF) shl 8) or (pcmData[i].toInt() and 0xFF)
                            val floatSample = sample.toShort().toFloat() / Short.MAX_VALUE
                            samples.add(floatSample)
                            samplesRead++
                        }
                    }
                    
                    decoder.releaseOutputBuffer(outputBufferIndex, false)
                }
            }
            
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error extracting audio samples", e)
        } finally {
            try {
                decoder?.stop()
                decoder?.release()
                extractor?.release()
            } catch (e: Exception) {
                CrashLogger.log("AudioManager", "Error releasing resources", e)
            }
        }
        
        return samples.toFloatArray()
    }
    
    private fun extractAudioSamplesFast(musicFile: MusicFile): FloatArray {
        val samples = mutableListOf<Float>()
        var extractor: MediaExtractor? = null
        var decoder: MediaCodec? = null
        
        try {
            extractor = MediaExtractor()
            
            // Check if it's an AIF file and use special handling
            val isAifFile = musicFile.name.lowercase().endsWith(".aif") || musicFile.name.lowercase().endsWith(".aiff")
            
            if (isAifFile) {
                CrashLogger.log("AudioManager", "Processing AIF file: ${musicFile.name}")
                // For AIF files, try to use the converted WAV file if it exists
                // Look for files with pattern "aiff_converted_*.wav" in cache directory
                val cacheDir = context.cacheDir
                val wavFiles = cacheDir.listFiles { file -> 
                    file.name.startsWith("aiff_converted_") && file.name.endsWith(".wav")
                }
                
                if (wavFiles != null && wavFiles.isNotEmpty()) {
                    // Use the most recently created WAV file
                    val convertedWavFile = wavFiles.maxByOrNull { it.lastModified() }
                    if (convertedWavFile != null) {
                        CrashLogger.log("AudioManager", "AIF: Using converted WAV file for spectrogram: ${convertedWavFile.name}")
                        try {
                            extractor.setDataSource(convertedWavFile.absolutePath)
                            CrashLogger.log("AudioManager", "AIF: Converted WAV data source successful")
                        } catch (e: Exception) {
                            CrashLogger.log("AudioManager", "AIF: Converted WAV data source failed", e)
                            // Fallback to original AIF file
                            try {
                                extractor.setDataSource(context, musicFile.uri, null)
                                CrashLogger.log("AudioManager", "AIF: Fallback to original AIF successful")
                            } catch (e2: Exception) {
                                CrashLogger.log("AudioManager", "AIF: All data source methods failed", e2)
                                return FloatArray(0)
                            }
                        }
                    } else {
                        CrashLogger.log("AudioManager", "AIF: No valid converted WAV file found, trying original AIF")
                        // Fall through to original AIF processing
                    }
                } else {
                    CrashLogger.log("AudioManager", "AIF: No converted WAV files found, trying original AIF")
                    // Try original AIF file with multiple methods
                    var dataSourceSuccess = false
                    
                    // Method 1: Standard context + URI
                    try {
                        extractor.setDataSource(context, musicFile.uri, null)
                        dataSourceSuccess = true
                        CrashLogger.log("AudioManager", "AIF: Primary data source successful")
                    } catch (e: Exception) {
                        CrashLogger.log("AudioManager", "AIF: Primary data source failed", e)
                    }
                    
                    // Method 2: URI string only
                    if (!dataSourceSuccess) {
                        try {
                            extractor.setDataSource(musicFile.uri.toString())
                            dataSourceSuccess = true
                            CrashLogger.log("AudioManager", "AIF: URI string data source successful")
                        } catch (e: Exception) {
                            CrashLogger.log("AudioManager", "AIF: URI string data source failed", e)
                        }
                    }
                    
                    // Method 3: File path
                    if (!dataSourceSuccess) {
                        try {
                            val filePath = musicFile.uri.path
                            if (filePath != null) {
                                extractor.setDataSource(filePath)
                                dataSourceSuccess = true
                                CrashLogger.log("AudioManager", "AIF: File path data source successful")
                            }
                        } catch (e: Exception) {
                            CrashLogger.log("AudioManager", "AIF: File path data source failed", e)
                        }
                    }
                    
                    if (!dataSourceSuccess) {
                        CrashLogger.log("AudioManager", "AIF: All data source methods failed")
                        return FloatArray(0)
                    }
                }
            } else {
                // Standard handling for other formats
                extractor.setDataSource(context, musicFile.uri, null)
            }
            
            // Find audio track with AIF-specific preferences
            var audioTrackIndex = -1
            var bestFormat: MediaFormat? = null
            
            CrashLogger.log("AudioManager", "AIF: Track count: ${extractor.trackCount}")
            
            for (i in 0 until extractor.trackCount) {
                val format = extractor.getTrackFormat(i)
                val mime = format.getString(MediaFormat.KEY_MIME)
                
                if (isAifFile) {
                    CrashLogger.log("AudioManager", "AIF: Track $i MIME: $mime")
                }
                
                if (mime?.startsWith("audio/") == true) {
                    if (isAifFile) {
                        // For AIF files, prefer uncompressed formats
                        if (mime.contains("pcm") || mime.contains("raw") || mime == "audio/aiff") {
                            audioTrackIndex = i
                            bestFormat = format
                            CrashLogger.log("AudioManager", "AIF: Selected preferred track $i with MIME: $mime")
                            break
                        } else if (audioTrackIndex == -1) {
                            // Fallback to any audio track
                            audioTrackIndex = i
                            bestFormat = format
                            CrashLogger.log("AudioManager", "AIF: Selected fallback track $i with MIME: $mime")
                        }
                    } else {
                        // For other formats, use first audio track
                        audioTrackIndex = i
                        bestFormat = format
                        break
                    }
                }
            }
            
            if (audioTrackIndex == -1) {
                CrashLogger.log("AudioManager", "AIF: No audio track found!")
                return FloatArray(0)
            }
            
            CrashLogger.log("AudioManager", "AIF: Using track $audioTrackIndex")
            
            extractor.selectTrack(audioTrackIndex)
            val format = bestFormat ?: extractor.getTrackFormat(audioTrackIndex)
            
            // Create decoder with AIF-specific error handling
            val mime = format.getString(MediaFormat.KEY_MIME) ?: return FloatArray(0)
            
            if (isAifFile) {
                CrashLogger.log("AudioManager", "AIF: Creating decoder for MIME: $mime")
                // Special decoder creation for AIF files with multiple fallbacks
                var decoderSuccess = false
                
                // Try original MIME type
                try {
                    decoder = MediaCodec.createDecoderByType(mime)
                    decoderSuccess = true
                    CrashLogger.log("AudioManager", "AIF: Primary decoder successful")
                } catch (e: Exception) {
                    CrashLogger.log("AudioManager", "AIF: Primary decoder failed", e)
                }
                
                // Try alternative MIME types
                if (!decoderSuccess) {
                    val alternativeMimes = listOf("audio/pcm", "audio/raw", "audio/wav", "audio/mp4")
                    for (altMime in alternativeMimes) {
                        try {
                            decoder = MediaCodec.createDecoderByType(altMime)
                            decoderSuccess = true
                            CrashLogger.log("AudioManager", "AIF: Alternative decoder successful with $altMime")
                            break
                        } catch (e: Exception) {
                            CrashLogger.log("AudioManager", "AIF: Alternative decoder failed with $altMime", e)
                        }
                    }
                }
                
                if (!decoderSuccess) {
                    CrashLogger.log("AudioManager", "AIF: All decoder creation methods failed")
                    return FloatArray(0)
                }
            } else {
                // Standard decoder creation for other formats
                decoder = MediaCodec.createDecoderByType(mime)
            }
            
            decoder?.configure(format, null, null, 0)
            decoder?.start()
            
            if (isAifFile) {
                CrashLogger.log("AudioManager", "AIF: Decoder configured and started")
            }
            
            val inputBuffers = decoder?.inputBuffers
            val outputBuffers = decoder?.outputBuffers
            
            if (inputBuffers == null || outputBuffers == null) {
                CrashLogger.log("AudioManager", "AIF: Failed to get decoder buffers")
                return FloatArray(0)
            }
            val bufferInfo = MediaCodec.BufferInfo()
            
            // AIF-specific sampling parameters
            val maxSamples = if (isAifFile) {
                44100 * 5 // 5 seconds for AIF files (prevent freezing)
            } else {
                44100 * 4 // 4 seconds for other formats (prevent freezing)
            }
            var samplesRead = 0
            var frameCount = 0
            var endOfStream = false
            
            val maxFrames = if (isAifFile) {
                50 // Very reduced frames for AIF files (prevent freezing)
            } else {
                40 // Very reduced frames for other formats (prevent freezing)
            }
            
            val timeout = if (isAifFile) 5000L else 3000L // Longer timeout for AIF files
            
            if (isAifFile) {
                CrashLogger.log("AudioManager", "AIF: Starting sample extraction - maxSamples: $maxSamples, maxFrames: $maxFrames")
            }
            
            while (!endOfStream && frameCount < maxFrames) {
                val inputBufferIndex = decoder?.dequeueInputBuffer(timeout) ?: -1
                if (inputBufferIndex >= 0) {
                    val inputBuffer = inputBuffers[inputBufferIndex]
                    val sampleSize = extractor.readSampleData(inputBuffer, 0)
                    
                    if (sampleSize < 0) {
                        decoder?.queueInputBuffer(inputBufferIndex, 0, 0, 0, MediaCodec.BUFFER_FLAG_END_OF_STREAM)
                        endOfStream = true
                    } else {
                        decoder?.queueInputBuffer(inputBufferIndex, 0, sampleSize, extractor.sampleTime, 0)
                        extractor.advance()
                    }
                }
                
                val outputBufferIndex = decoder?.dequeueOutputBuffer(bufferInfo, timeout) ?: -1
                if (outputBufferIndex >= 0) {
                    val outputBuffer = outputBuffers[outputBufferIndex]
                    val pcmData = ByteArray(bufferInfo.size)
                    outputBuffer.get(pcmData)
                    
                    // AIF-specific sample processing
                    val stepSize = if (isAifFile) {
                        4 // Every 4th sample for AIF files (optimized for reduced resolution)
                    } else {
                        6 // Every 6th sample for other formats (optimized for reduced resolution)
                    }
                    
                    for (i in pcmData.indices step stepSize) {
                        if (i + 1 < pcmData.size && samplesRead < maxSamples) {
                            val sample = ((pcmData[i + 1].toInt() and 0xFF) shl 8) or (pcmData[i].toInt() and 0xFF)
                            val floatSample = sample.toShort().toFloat() / Short.MAX_VALUE
                            samples.add(floatSample)
                            samplesRead++
                        }
                    }
                    
                    decoder?.releaseOutputBuffer(outputBufferIndex, false)
                    frameCount++
                    
                    // Check for end of stream
                    if ((bufferInfo.flags and MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0) {
                        endOfStream = true
                    }
                }
            }
            
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error extracting audio samples fast", e)
        } finally {
            try {
                decoder?.stop()
                decoder?.release()
                extractor?.release()
            } catch (e: Exception) {
                CrashLogger.log("AudioManager", "Error releasing resources", e)
            }
        }
        
        val result = samples.toFloatArray()
        val isAifFile = musicFile.name.lowercase().endsWith(".aif") || musicFile.name.lowercase().endsWith(".aiff")
        if (isAifFile) {
            CrashLogger.log("AudioManager", "AIF: Extraction complete - ${result.size} samples extracted")
        }
        return result
    }
    
    fun createFastSpectrogram(audioData: FloatArray): ImageBitmap {
        val width = 150   // Much reduced width to prevent freezing
        val height = 200  // Much reduced height to prevent freezing
        val pixels = IntArray(width * height)
        
        // Sample rate (assuming 44.1kHz)
        val sampleRate = 44100f
        
        // Create logarithmic frequency bands (20Hz to 22kHz)
        val freqBands = createLogFrequencyBands(height, 20f, 22000f)
        
        // Ensure entire song is covered with proper time mapping
        val frameSize = maxOf(1024, audioData.size / width)
        val hopSize = maxOf(1, audioData.size / width) // Ensure complete coverage
        
        for (x in 0 until width) {
            // Map X position to time position across entire song
            val timePosition = x.toFloat() / (width - 1) // 0.0 to 1.0
            val startSample = (timePosition * (audioData.size - frameSize)).toInt().coerceAtLeast(0)
            val endSample = minOf(startSample + frameSize, audioData.size)
            
            // Extract frame
            val frame = if (startSample < audioData.size && endSample > startSample) {
                audioData.sliceArray(startSample until endSample)
            } else {
                val lastStart = maxOf(0, audioData.size - frameSize)
                audioData.sliceArray(lastStart until audioData.size)
            }
            
            // Calculate frequency response for each band using improved RMS
            val bandValues = FloatArray(height)
            
            for (band in 0 until height) {
                val freqRange = freqBands[band]
                val magnitude = calculateBandMagnitude(frame, freqRange, sampleRate)
                bandValues[band] = magnitude
            }
            
            // Map to spectrogram with proper frequency response
            for (y in 0 until height) {
                val bandIndex = height - 1 - y // 0 dB on top
                val magnitude = bandValues[bandIndex]
                
                // Convert to dB scale (-60 to 0 dB) for power spectrum
                val db = if (magnitude > 0f) {
                    val linear = magnitude.coerceIn(0.001f, 1f) // -60dB range
                    20f * kotlin.math.log10(linear).toFloat()
                } else {
                    -60f
                }
                
                // Normalize dB to 0-1 range (-60dB to 0dB)
                val normalizedDb = (db + 60f) / 60f
                
                // Lateral perspective: X=time, Y=frequency, Z=dB (viewed from the side)
                val color = getPowerSpectrumColor(normalizedDb, x, y, width, height)
                    
                    pixels[(height - 1 - y) * width + x] = color
            }
        }
        
        // Create Android Bitmap then convert to Compose ImageBitmap
        val bitmap = android.graphics.Bitmap.createBitmap(
            width,
            height,
            android.graphics.Bitmap.Config.ARGB_8888
        )
        bitmap.setPixels(pixels, 0, width, 0, 0, width, height)
        return bitmap.asImageBitmap()
    }
    
    private fun createLogFrequencyBands(numBands: Int, minFreq: Float, maxFreq: Float): Array<Pair<Float, Float>> {
        val bands = Array(numBands) { Pair(0f, 0f) }
        
        // Simple logarithmic distribution
        val logMin = kotlin.math.log10(minFreq)
        val logMax = kotlin.math.log10(maxFreq)
        val logRange = logMax - logMin
        
        for (i in 0 until numBands) {
            val logStart = logMin + (i * logRange / numBands)
            val logEnd = logMin + ((i + 1) * logRange / numBands)
            val freqStart = kotlin.math.exp(logStart * kotlin.math.ln(10f))
            val freqEnd = kotlin.math.exp(logEnd * kotlin.math.ln(10f))
            bands[i] = Pair(freqStart, freqEnd)
        }
        
        return bands
    }
    
    
    private fun calculateBandMagnitude(frame: FloatArray, freqRange: Pair<Float, Float>, sampleRate: Float): Float {
        val (freqStart, freqEnd) = freqRange
        
        // Convert frequency range to sample indices
        val startIndex = (freqStart * frame.size / sampleRate).toInt().coerceAtLeast(0)
        val endIndex = (freqEnd * frame.size / sampleRate).toInt().coerceAtMost(frame.size)
        
        if (startIndex >= endIndex) return 0f
        
        // Calculate RMS for this frequency band with professional accuracy
        var sum = 0f
        val step = maxOf(1, (endIndex - startIndex) / 8) // Optimized sampling for reduced resolution
        
        for (i in startIndex until endIndex step step) {
            sum += frame[i] * frame[i]
        }
        
        val rms = kotlin.math.sqrt(sum / ((endIndex - startIndex) / step))
        return rms.coerceAtLeast(0.000000001f) // Ultra-high sensitivity for detailed amplitude reading
    }
    
    private fun getFrequencyResponseColor(normalizedDb: Float, bandIndex: Int, totalBands: Int): Int {
        // 3D-style color mapping with height/depth visualization
        return when {
            normalizedDb < 0.0f -> 0xFF000000.toInt() // Black (no signal)
            normalizedDb < 0.1f -> 0xFF001122.toInt() // Very dark blue (lowest)
            normalizedDb < 0.2f -> 0xFF002244.toInt() // Dark blue
            normalizedDb < 0.3f -> 0xFF003366.toInt() // Blue
            normalizedDb < 0.4f -> 0xFF004488.toInt() // Medium blue
            normalizedDb < 0.5f -> 0xFF0055AA.toInt() // Bright blue
            normalizedDb < 0.6f -> 0xFF0066CC.toInt() // Cyan blue
            normalizedDb < 0.7f -> 0xFF0077DD.toInt() // Light cyan
            normalizedDb < 0.8f -> 0xFF0088EE.toInt() // Bright cyan
            normalizedDb < 0.85f -> 0xFF0099FF.toInt() // Pure cyan
            normalizedDb < 0.9f -> 0xFF00AAFF.toInt() // Light green
            normalizedDb < 0.92f -> 0xFF00BBFF.toInt() // Green
            normalizedDb < 0.94f -> 0xFF00CCFF.toInt() // Bright green
            normalizedDb < 0.96f -> 0xFF00DDFF.toInt() // Yellow green
            normalizedDb < 0.97f -> 0xFF00EEFF.toInt() // Yellow
            normalizedDb < 0.98f -> 0xFF00FFFF.toInt() // Bright yellow
            normalizedDb < 0.99f -> 0xFF44FFFF.toInt() // Orange
            else -> 0xFF88FFFF.toInt() // Bright white (peak intensity)
        }
    }
    
    
    private fun getPowerSpectrumColor(normalizedPower: Float, x: Int, y: Int, width: Int, height: Int): Int {
        // Power spectrum: LATERAL perspective with power values (0.0 to 1.0)
        // Higher power = extends further from screen = brighter color with depth
        // Lower power = closer to screen = darker color
        // Power spectrum emphasizes energy content more than magnitude
        
        // Create lateral perspective with depth and lighting effects
        val depthLevel = normalizedPower // Use power as depth level
        
        // Add lateral lighting effect (brighter on the "front" side)
        val lightingFactor = 0.3f + (depthLevel * 0.7f) // 0.3 to 1.0 lighting
        
        // Add depth shading (darker as it goes "back")
        val depthShading = 1.0f - (depthLevel * 0.4f) // 1.0 to 0.6 shading
        
        // Base color based on power level (emphasizes energy content)
        val baseColor = when {
            depthLevel < 0.001f -> 0xFF000000.toInt() // Black (no power)
            depthLevel < 0.01f -> 0xFF001122.toInt() // Very dark blue (very low power)
            depthLevel < 0.05f -> 0xFF002244.toInt() // Dark blue (low power)
            depthLevel < 0.1f -> 0xFF003366.toInt() // Blue (low-medium power)
            depthLevel < 0.15f -> 0xFF004488.toInt() // Medium blue
            depthLevel < 0.2f -> 0xFF0055AA.toInt() // Bright blue
            depthLevel < 0.25f -> 0xFF0066CC.toInt() // Cyan blue
            depthLevel < 0.3f -> 0xFF0077DD.toInt() // Light cyan
            depthLevel < 0.35f -> 0xFF0088EE.toInt() // Bright cyan
            depthLevel < 0.4f -> 0xFF0099FF.toInt() // Pure cyan
            depthLevel < 0.45f -> 0xFF00AAFF.toInt() // Light green
            depthLevel < 0.5f -> 0xFF00BBFF.toInt() // Green
            depthLevel < 0.55f -> 0xFF00CCFF.toInt() // Bright green
            depthLevel < 0.6f -> 0xFF00DDFF.toInt() // Yellow green
            depthLevel < 0.65f -> 0xFF00EEFF.toInt() // Yellow
            depthLevel < 0.7f -> 0xFF00FFFF.toInt() // Bright yellow
            depthLevel < 0.75f -> 0xFF44FFFF.toInt() // Orange
            depthLevel < 0.8f -> 0xFF88FFFF.toInt() // Light orange
            depthLevel < 0.85f -> 0xFFCCFFFF.toInt() // White
            depthLevel < 0.9f -> 0xFFEEFFFF.toInt() // Bright white
            else -> 0xFFFFFFFF.toInt() // Maximum white (highest power)
        }
        
        // Apply lateral lighting and depth effects
        val r = ((baseColor shr 16) and 0xFF) * lightingFactor * depthShading
        val g = ((baseColor shr 8) and 0xFF) * lightingFactor * depthShading
        val b = (baseColor and 0xFF) * lightingFactor * depthShading
        
        return (0xFF000000.toInt() or 
                ((r.toInt() and 0xFF) shl 16) or 
                ((g.toInt() and 0xFF) shl 8) or 
                (b.toInt() and 0xFF))
    }
    
    
    private fun createOptimizedFFTSpectrogram(audioData: FloatArray): ImageBitmap {
        val width = 256  // Reduced resolution for performance
        val height = 128 // Reduced resolution for performance
        val fftSize = 512 // Smaller FFT size for performance
        val hopSize = fftSize / 2
        val numFrames = (audioData.size - fftSize) / hopSize + 1
        
        // Create spectrogram data
        val spectrogramData = Array(height) { FloatArray(width) }
        
        // Process frames with reduced complexity
        for (x in 0 until width) {
            val frameIndex = (x * numFrames / width).coerceAtMost(numFrames - 1)
            val startSample = frameIndex * hopSize
            
            if (startSample + fftSize <= audioData.size) {
                // Extract frame for FFT
                val frame = FloatArray(fftSize)
                for (i in 0 until fftSize) {
                    frame[i] = audioData[startSample + i]
                }
                
                // Apply simplified window function
                for (i in 0 until fftSize) {
                    val window = 0.5f * (1f - kotlin.math.cos(2f * Math.PI.toFloat() * i / (fftSize - 1)))
                    frame[i] *= window
                }
                
                // Simplified FFT (magnitude spectrum only)
                val magnitude = FloatArray(fftSize / 2)
                for (k in 0 until fftSize / 2) {
                    var real = 0f
                    var imag = 0f
                    
                    // Reduced FFT computation
                    for (n in 0 until fftSize step 2) { // Skip every other sample for performance
                        val angle = -2f * Math.PI.toFloat() * k * n / fftSize
                        real += frame[n] * kotlin.math.cos(angle)
                        imag += frame[n] * kotlin.math.sin(angle)
                    }
                    
                    magnitude[k] = kotlin.math.sqrt(real * real + imag * imag)
                }
                
                // Map to spectrogram height (frequency bins) - 0 dB ON TOP
                for (y in 0 until height) {
                    val freqBin = (y * magnitude.size / height).coerceAtMost(magnitude.size - 1)
                    spectrogramData[height - 1 - y][x] = magnitude[freqBin] // 0 dB on top: height-1-y
                }
            }
        }
        
        // Normalize and convert to colors with enhanced visibility
        val maxMagnitude = spectrogramData.maxOfOrNull { row -> row.maxOrNull() ?: 0f } ?: 1f
        val pixels = IntArray(width * height)
        
        for (x in 0 until width) {
            for (y in 0 until height) {
                val magnitude = spectrogramData[y][x] / maxMagnitude
                
                // Enhanced intensity calculation for better visibility
                val intensity = if (magnitude > 0f) {
                    kotlin.math.log10(magnitude * 999f + 1f) / kotlin.math.log10(1000f)
                } else {
                    0f
                }
                
                // Convert to dB scale (-120 to 0 dB range) like professional spectrograms
                val db = intensity * 120f - 120f // Convert to -120 to 0 dB range
                val color = when {
                    db < -100f -> 0xFF000000.toInt() // Black (-120 dB)
                    db < -80f -> 0xFF1A0033.toInt() // Very dark purple (-100 dB)
                    db < -60f -> 0xFF330066.toInt() // Dark purple (-80 dB)
                    db < -40f -> 0xFF6600CC.toInt() // Purple (-60 dB)
                    db < -20f -> 0xFFCC0066.toInt() // Dark red (-40 dB)
                    else -> 0xFFFFFF00.toInt() // Bright yellow (0 dB)
                }
                
                pixels[y * width + x] = color
            }
        }
        
        // Create Android Bitmap then convert to Compose ImageBitmap
        val bitmap = android.graphics.Bitmap.createBitmap(
            width,
            height,
            android.graphics.Bitmap.Config.ARGB_8888
        )
        bitmap.setPixels(pixels, 0, width, 0, 0, width, height)
        return bitmap.asImageBitmap()
    }
    
    private fun createFallbackSpectrogram(musicFile: MusicFile): ImageBitmap {
        val width = 2133  // Match balanced resolution (reduced by 3x)
        val height = 1067  // Match balanced resolution (reduced by 3x)
        val pixels = IntArray(width * height)
        
        // Create a synthetic spectrogram based on file properties
        val fileName = musicFile.name.lowercase()
        val hash = fileName.hashCode()
        val random = kotlin.random.Random(hash)
        
        for (x in 0 until width) {
            val timePosition = x.toFloat() / width
            
            for (y in 0 until height) {
                val freqPosition = y.toFloat() / height
                
                // Create frequency content based on time and frequency
                var intensity = 0f
                
                // Base frequency response (lower frequencies are typically louder)
                intensity += (1f - freqPosition) * 0.7f // Increased base intensity
                
                // Add some time-varying content
                intensity += 0.4f * kotlin.math.sin(timePosition * Math.PI * 4).toFloat()
                intensity += 0.3f * kotlin.math.sin(freqPosition * Math.PI * 8).toFloat()
                
                // Add some random variation
                intensity += (random.nextFloat() - 0.5f) * 0.3f
                
                // Create some frequency bands with more contrast
                when {
                    freqPosition < 0.2f -> intensity *= 1.0f // Low frequencies
                    freqPosition < 0.4f -> intensity *= 1.3f // Mid-low frequencies
                    freqPosition < 0.6f -> intensity *= 1.1f // Mid frequencies
                    freqPosition < 0.8f -> intensity *= 0.8f // Mid-high frequencies
                    else -> intensity *= 0.6f // High frequencies
                }
                
                // Add some time-based variations (intro, main, outro)
                when {
                    timePosition < 0.1f -> intensity *= 0.6f // Intro
                    timePosition < 0.9f -> intensity *= 1.0f // Main
                    else -> intensity *= 0.7f // Outro
                }
                
                // Convert intensity to color with better contrast
                intensity = intensity.coerceIn(0f, 1f)
                val color = when {
                    intensity < 0.2f -> 0xFF000000.toInt() // Black
                    intensity < 0.4f -> 0xFF1A1A2E.toInt() // Dark blue
                    intensity < 0.6f -> 0xFF16213E.toInt() // Blue
                    intensity < 0.8f -> 0xFF0F3460.toInt() // Light blue
                    else -> 0xFFE94560.toInt() // Red
                }
                
                pixels[y * width + x] = color
            }
        }
        
        // Create Android Bitmap then convert to Compose ImageBitmap
        val bitmap = android.graphics.Bitmap.createBitmap(
            width,
            height,
            android.graphics.Bitmap.Config.ARGB_8888
        )
        bitmap.setPixels(pixels, 0, width, 0, 0, width, height)
        return bitmap.asImageBitmap()
    }
    
    private fun createWaveform(audioData: FloatArray): FloatArray {
        val targetSamples = 1000 // Number of waveform points
        val samplesPerPoint = audioData.size / targetSamples
        val waveform = FloatArray(targetSamples)
        
        for (i in 0 until targetSamples) {
            val startIndex = i * samplesPerPoint
            val endIndex = minOf(startIndex + samplesPerPoint, audioData.size)
            
            if (startIndex < audioData.size) {
                var maxAmplitude = 0f
                for (j in startIndex until endIndex) {
                    maxAmplitude = maxOf(maxAmplitude, kotlin.math.abs(audioData[j]))
                }
                waveform[i] = maxAmplitude
            }
        }
        
        return waveform
    }
    
    // Enhanced spectrogram with better color mapping
    private fun createSpectrogram(audioData: FloatArray): ImageBitmap {
        val width = 512
        val height = 256
        val fftSize = 1024
        
        // Create a more detailed spectrogram visualization
        val pixels = IntArray(width * height)
        
        for (x in 0 until width) {
            val startIndex = (x * audioData.size / width).toInt()
            val endIndex = minOf(startIndex + fftSize, audioData.size)
            
            if (startIndex < audioData.size) {
                val segment = audioData.slice(startIndex until endIndex)
                val spectrum = computeSpectrum(segment, fftSize)
                
                for (y in 0 until height) {
                    val freqIndex = (y * spectrum.size / height).toInt()
                    val magnitude = if (freqIndex < spectrum.size) spectrum[freqIndex] else 0f
                    
                    // Theme-neutral color mapping
                    val intensity = (magnitude * 4f).coerceIn(0f, 1f)
                    val color = when {
                        intensity < 0.1f -> 0xFF2D2D2D.toInt() // Dark gray for silence
                        intensity < 0.3f -> 0xFF404040.toInt() // Medium dark gray
                        intensity < 0.5f -> 0xFF606060.toInt() // Medium gray
                        intensity < 0.7f -> 0xFF808080.toInt() // Light gray
                        intensity < 0.9f -> 0xFFA0A0A0.toInt() // Lighter gray
                        else -> 0xFFC0C0C0.toInt() // Lightest gray for loudest
                    }
                    
                    pixels[y * width + x] = color
                }
            }
        }
        
        // Create Android Bitmap then convert to Compose ImageBitmap
        val bitmap = android.graphics.Bitmap.createBitmap(
            width,
            height,
            android.graphics.Bitmap.Config.ARGB_8888
        )
        bitmap.setPixels(pixels, 0, width, 0, 0, width, height)
        return bitmap.asImageBitmap()
    }
    
    private fun getDurationFromUri(uri: Uri): Long {
        return try {
            val retriever = android.media.MediaMetadataRetriever()
            retriever.setDataSource(context, uri)
            val duration = retriever.extractMetadata(android.media.MediaMetadataRetriever.METADATA_KEY_DURATION)
            retriever.release()
            duration?.toLong() ?: 0L
        } catch (e: Exception) {
            CrashLogger.log("AudioManager", "Error getting duration for $uri", e)
            0L
        }
    }
    
    fun clearAllCaches() {
        spectrogramCache.clear()
        coverArtCache.clear()
        CrashLogger.log("AudioManager", "All caches cleared to free memory")
    }
    
    fun getCacheSize(): String {
        val spectrogramSize = spectrogramCache.size
        val coverArtSize = coverArtCache.size
        val totalSize = spectrogramSize + coverArtSize
        return "Cache: Spectrogram($spectrogramSize), CoverArt($coverArtSize), Total($totalSize)"
    }
    
    fun release() {
        player?.release()
        mediaSession?.release()
        fallbackMediaPlayer?.release()
        player = null
        mediaSession = null
        fallbackMediaPlayer = null
    }
}
